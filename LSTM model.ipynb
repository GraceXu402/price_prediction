{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "93dd3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc,accuracy_score\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c846c",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "18f19411",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_min_return = pd.read_csv('btc_min_return_selected.csv')\n",
    "btc_min_return.index =pd.to_datetime(btc_min_return['timestamp'])\n",
    "btc_min_return.drop(columns=['timestamp'],inplace=True)\n",
    "btc_min_return=btc_min_return[btc_min_return.index > '2019']\n",
    "btc_min_return['return_scaled'] = btc_min_return['return']*100\n",
    "\n",
    "features_removed = ['return','return_scaled','J_test_stats', 'jump_detected_3_3','jump_size_3_3','RV_d','log1+J','RS','scale_right','shape_right','scale_left','shape_left']\n",
    "\n",
    "features = btc_min_return.columns.to_list()\n",
    "features = [item for item in features if item not in features_removed]\n",
    "TI_features = features[:6]+features[-17:]\n",
    "SV_features = features[:-17]\n",
    "Naive_features = features[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cfb8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_hourly_return = pd.read_csv('btc_hourly_return_selected.csv')\n",
    "btc_hourly_return.index =pd.to_datetime(btc_hourly_return['timestamp'])\n",
    "btc_hourly_return.drop(columns=['timestamp'],inplace=True)\n",
    "#btc_min_return=btc_min_return[btc_min_return.index > '2019']\n",
    "btc_hourly_return['return_scaled'] = btc_hourly_return['return']*100\n",
    "\n",
    "features_removed = ['return','return_scaled','J_test_stats', 'jump_detected_3_3','jump_size_3_3','RV_d','log1+J','RS','scale_right','shape_right','scale_left','shape_left']\n",
    "features = btc_min_return.columns.to_list()\n",
    "features = [item for item in features if item not in features_removed]\n",
    "TI_features = features[:6]+features[-17:]\n",
    "SV_features = features[:-17]\n",
    "Naive_features = features[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "613a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_daily_return = pd.read_csv('btc_daily_return_selected.csv')\n",
    "btc_daily_return.index =pd.to_datetime(btc_daily_return['timestamp'])\n",
    "btc_daily_return.drop(columns=['timestamp'],inplace=True)\n",
    "#btc_min_return=btc_min_return[btc_min_return.index > '2019']\n",
    "btc_daily_return['return_scaled'] = btc_daily_return['return']*100\n",
    "\n",
    "features_removed = ['return','return_scaled','J_test_stats', 'jump_detected_3_3','jump_size_3_3','RV_d','log1+J','RS','scale_right','shape_right','scale_left','shape_left']\n",
    "features = btc_daily_return.columns.to_list()\n",
    "features = [item for item in features if item not in features_removed]\n",
    "TI_features = features[:6]+features[-17:]\n",
    "SV_features = features[:-17]\n",
    "Naive_features = features[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867df2f7",
   "metadata": {},
   "source": [
    "### Generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6f29d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_upper = 0.8\n",
    "quantile_lower = 1-quantile_upper\n",
    "accuracy_metric = 'Build_in_acc'\n",
    "target_used = 'target_quantile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3cda48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04844716058581401, -0.048522686341572016]\n"
     ]
    }
   ],
   "source": [
    "# Create the target variable -- Quantile based threshold\n",
    "upper_quantile = btc_min_return['return_scaled'].quantile(quantile_upper)\n",
    "lower_quantile = btc_min_return['return_scaled'].quantile(quantile_lower)\n",
    "btc_min_return['target_quantile'] = 0\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) > upper_quantile, 'target_quantile'] = 1\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) < lower_quantile, 'target_quantile'] = -1\n",
    "btc_min_return = btc_min_return.dropna()\n",
    "print([upper_quantile,lower_quantile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "eb150274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = btc_min_return.copy()\n",
    "X = df[features]\n",
    "y = df[target_used]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "cutoff_date = '2021-01-01'\n",
    "X_train = X[btc_min_return.index < cutoff_date]\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = X[btc_min_return.index >= cutoff_date]\n",
    "scaler = StandardScaler()\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "y_train = y[btc_min_return.index < cutoff_date]\n",
    "y_test = y[btc_min_return.index >= cutoff_date]\n",
    "\n",
    "X_TI = df[TI_features]\n",
    "X_train_TI = X_TI[df[TI_features].index < cutoff_date]\n",
    "scaler = StandardScaler()\n",
    "X_train_TI= scaler.fit_transform(X_train_TI)\n",
    "X_test_TI = X_TI[df[TI_features].index >= cutoff_date]\n",
    "scaler = StandardScaler()\n",
    "X_test_TI= scaler.fit_transform(X_test_TI)\n",
    "\n",
    "X_SV = df[SV_features]\n",
    "scaler = StandardScaler()\n",
    "X_SV= scaler.fit_transform(X_SV)\n",
    "X_train_SV = X_SV[df[SV_features].index < cutoff_date]\n",
    "X_test_SV = X_SV[df[SV_features].index >= cutoff_date]\n",
    "\n",
    "X_Naive = df[Naive_features]\n",
    "scaler = StandardScaler()\n",
    "X_Naive= scaler.fit_transform(X_Naive)\n",
    "X_train_Naive = X_Naive[df[Naive_features].index < cutoff_date]\n",
    "X_test_Naive = X_Naive[df[Naive_features].index >= cutoff_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6afea4",
   "metadata": {},
   "source": [
    "#### Histogram Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb59af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(btc_min_return)/200/60/24) # roughly ten days per bin\n",
    "number_of_bins = 300\n",
    "bin_counts, bin_edges = np.histogram(btc_min_return['return_scaled'], bins=number_of_bins)\n",
    "\n",
    "sorted_indices = np.argsort(bin_counts)[::-1]\n",
    "sorted_bin_counts = bin_counts[sorted_indices]\n",
    "sorted_bin_edges = bin_edges[sorted_indices]\n",
    "\n",
    "original_bin_edges = bin_edges\n",
    "cumulative_counts = np.cumsum(sorted_bin_counts)\n",
    "total_count = len(btc_min_return)  \n",
    "threshold_count_upper = 0.8 * total_count\n",
    "threshold_count_lower = 0.2 * total_count\n",
    "\n",
    "threshold_bin_index_upper = np.where(cumulative_counts >= threshold_count_upper)[0][0]\n",
    "threshold_upper_bound = original_bin_edges[sorted_indices[threshold_bin_index_upper] + 1] if threshold_bin_index_upper < len(original_bin_edges) - 1 else original_bin_edges[-1]\n",
    "threshold_bin_index_lower = np.where(cumulative_counts >= threshold_count_lower)[0][0]\n",
    "threshold_lower_bound = original_bin_edges[sorted_indices[threshold_bin_index_lower]]\n",
    "print(f'Upper bound of the threshold value: {threshold_upper_bound}')\n",
    "print(f'Lower bound of the threshold value: {threshold_lower_bound}')\n",
    "\n",
    "btc_min_return['target_hist'] = 0\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) > threshold_upper_bound, 'target_hist'] = 1\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) < threshold_lower_bound, 'target_hist'] = -1\n",
    "btc_min_return = btc_min_return.dropna()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(btc_min_return['return_scaled'], bins=number_of_bins, edgecolor='k', alpha=0.7)\n",
    "plt.title('Histogram of BTC Min Returns')\n",
    "plt.xlabel('Return Scaled')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate entropy\n",
    "def calculate_entropy(labels):\n",
    "    label_counts = np.bincount(labels.astype(int))\n",
    "    return entropy(label_counts, base=2)\n",
    "\n",
    "def calculate_best_thresholds(close_diff, threshold_upper_bound):\n",
    "    best_entropy_upper = -np.inf\n",
    "    best_threshold_upper = 0\n",
    "\n",
    "    # Upper threshold search\n",
    "    temp_threshold = 0\n",
    "    while temp_threshold < threshold_upper_bound:\n",
    "        labels = np.zeros(len(close_diff))\n",
    "        indexes_incr = np.where(close_diff > temp_threshold)[0]\n",
    "        indexes_decr = np.where(-close_diff > temp_threshold)[0]\n",
    "\n",
    "        labels[indexes_incr] = 2\n",
    "        labels[indexes_decr] = 1\n",
    "\n",
    "        current_entropy = calculate_entropy(labels)\n",
    "\n",
    "        if current_entropy > best_entropy_upper:\n",
    "            best_entropy_upper = current_entropy\n",
    "            best_threshold_upper = temp_threshold\n",
    "\n",
    "        temp_threshold += 0.00001\n",
    "\n",
    "    return best_threshold_upper\n",
    "\n",
    "# Applying the algorithm\n",
    "Entropy_upper_threshold = calculate_best_thresholds(btc_min_return['return_scaled'], threshold_upper_bound)\n",
    "print([Entropy_upper_threshold, -Entropy_upper_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_min_return['target_entropy'] = 0\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) > Entropy_upper_threshold, 'target_entropy'] = 1\n",
    "btc_min_return.loc[btc_min_return['return_scaled'].shift(-1) < -Entropy_upper_threshold, 'target_entropy'] = -1\n",
    "btc_min_return = btc_min_return.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a69012",
   "metadata": {},
   "source": [
    "### Define Accuracy metrics\n",
    "\n",
    "- Type I error: FP (reject null while null is true)\n",
    "\n",
    "- Type II error: FN (not reject null while null is not true)\n",
    "\n",
    "- Precision: $\\frac{TP}{TP + FP}$\n",
    "\n",
    "- Recall: $\\frac{TP}{TP + FN}$\n",
    "\n",
    "- F1-Score: $2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "\n",
    "- Accuracy_function:\n",
    "\n",
    "$\\text{Profit}-\\text{accuracy} = \\frac{TD + TI}{TD + TI + FDN+FIN+FID+FDI}$;\n",
    "\n",
    "s.t.\n",
    "TD: the number of true predictions decreases; FDN: the number of predictions of the no-action class decreases; FDI: the number of predictions of the increase class decreases and etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db132e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y_true, y_pred):\n",
    "    Accuracy = {}\n",
    "    \n",
    "    '''# Acc_Ignore_Pred_Neutral: Accuracy when ignoring neutral predictions\n",
    "    mask_pred_non_neutral = y_pred != 0\n",
    "    correct_pred_non_neutral = (y_true[mask_pred_non_neutral] == y_pred[mask_pred_non_neutral]).sum()\n",
    "    total_pred_non_neutral = mask_pred_non_neutral.sum()\n",
    "    Accuracy['Acc_Ignore_Pred_Neutral'] = (\n",
    "        correct_pred_non_neutral / total_pred_non_neutral \n",
    "        if total_pred_non_neutral > 0 \n",
    "        else 0\n",
    "    )\n",
    "    \n",
    "    # Acc_Ignore_True_Neutral: Accuracy when ignoring neutral true labels\n",
    "    mask_true_non_neutral = y_true != 0\n",
    "    correct_true_non_neutral = (y_true[mask_true_non_neutral] == y_pred[mask_true_non_neutral]).sum()\n",
    "    total_true_non_neutral = mask_true_non_neutral.sum()\n",
    "    Accuracy['Acc_Ignore_True_Neutral'] = (\n",
    "        correct_true_non_neutral / total_true_non_neutral \n",
    "        if total_true_non_neutral > 0 \n",
    "        else 0\n",
    "    )'''\n",
    "    \n",
    "    # Acc_True: Standard accuracy\n",
    "    Accuracy['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Round the accuracy values to 2 decimal places\n",
    "    Acc = {k: round(v, 2) for k, v in Accuracy.items()}\n",
    "    \n",
    "    # Return the accuracies as a DataFrame\n",
    "    return pd.DataFrame([Acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19018dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429c9d9e",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c6c0d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1_score(y_true, y_pred):\n",
    "    # Ensure y_true and y_pred are of integer type\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Convert to one-hot encoding for F1 score calculation\n",
    "    num_classes = tf.reduce_max(y_true) + 1\n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
    "    y_pred_one_hot = tf.one_hot(y_pred, depth=num_classes)\n",
    "    \n",
    "    # Calculate True Positives, False Positives, False Negatives\n",
    "    tp = K.sum(K.cast(y_true_one_hot * y_pred_one_hot, 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true_one_hot) * y_pred_one_hot, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true_one_hot * (1 - y_pred_one_hot), 'float32'), axis=0)\n",
    "    \n",
    "    # Calculate Precision, Recall\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    # Calculate F1 score for each class\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    \n",
    "    # Return the average F1 score across all classes\n",
    "    return K.mean(f1)\n",
    "\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    num_classes = tf.reduce_max(y_true) + 1\n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
    "    y_pred_one_hot = tf.one_hot(y_pred, depth=num_classes)\n",
    "    tp = K.sum(K.cast(y_true_one_hot * y_pred_one_hot, 'float32'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true_one_hot) * y_pred_one_hot, 'float32'), axis=0)\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    return K.mean(precision)\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    # Ensure y_true and y_pred are of integer type\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Convert to one-hot encoding for recall calculation\n",
    "    num_classes = tf.reduce_max(y_true) + 1\n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
    "    y_pred_one_hot = tf.one_hot(y_pred, depth=num_classes)\n",
    "    \n",
    "    # Calculate True Positives and False Negatives\n",
    "    tp = K.sum(K.cast(y_true_one_hot * y_pred_one_hot, 'float32'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true_one_hot * (1 - y_pred_one_hot), 'float32'), axis=0)\n",
    "    \n",
    "    # Calculate Recall for each class\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    # Return the average Recall across all classes\n",
    "    return K.mean(recall)\n",
    "\n",
    "def custom_auc(y_true, y_pred):\n",
    "    # Ensure y_true and y_pred are of integer type\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_pred = tf.nn.softmax(y_pred)  # Convert logits to probabilities\n",
    "    \n",
    "    # Define AUC metric\n",
    "    auc_metric = tf.keras.metrics.AUC()\n",
    "    \n",
    "    # Update the metric with the true labels and predictions\n",
    "    auc_metric.update_state(y_true, y_pred)\n",
    "    \n",
    "    # Return the result of AUC\n",
    "    return auc_metric.result()\n",
    "\n",
    "\n",
    "def plot_metrics(history, metric='accuracy'):\n",
    " \n",
    "    plt.figure(figsize=(6, 3))  # Adjust the figure size\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training and validation accuracy (or other metric)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if metric == 'accuracy':\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "    else:\n",
    "        plt.plot(history.history[metric], label=f'Training {metric.capitalize()}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=regularizers.l2(0.01))))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=regularizers.l2(0.01))))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(32, return_sequences=False, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_and_train_lstm(X_train, y_train, X_test, y_test, \n",
    "                         epochs=50, patience=6, learning_rate=0.005, \n",
    "                         metric=custom_f1_score, \n",
    "                         plot_metrics_flag=False):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Encoding the labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Reshaping the input data for LSTM\n",
    "    X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "    # Calculating class weights to handle imbalanced data\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Building the LSTM model\n",
    "    model = build_lstm_model(input_shape=(1, X_train_scaled.shape[1]), num_classes=len(label_encoder.classes_))\n",
    "\n",
    "    # Compiling the model with the specified optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=[metric,'accuracy'])\n",
    "    \n",
    "    # Setting up early stopping to prevent overfitting\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(X_train_lstm, y_train_encoded,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=64,\n",
    "                        verbose=2,\n",
    "                        validation_data=(X_test_lstm, y_test_encoded),\n",
    "                        callbacks=[early_stopping_callback],\n",
    "                        class_weight=class_weight_dict)\n",
    "\n",
    "    # Plotting the metrics if the flag is set\n",
    "    if plot_metrics_flag:\n",
    "        plot_metrics(history, metric='accuracy')  # This will plot both loss and accuracy curves\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    y_pred_prob = model.predict(X_test_lstm)\n",
    "    y_pred_encoded = np.argmax(y_pred_prob, axis=1)\n",
    "    y_pred_class = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "    return y_pred_prob, y_pred_class\n",
    "\n",
    "\n",
    "def evaluate_lstm_model(X_train, y_train, X_test, y_test, \n",
    "                        epochs_list, metric_list, learning_rate_list):\n",
    "    results = {}\n",
    "\n",
    "    # Iterate through each combination of epochs, metrics, and learning rates\n",
    "    for metric in metric_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            for epochs in epochs_list:\n",
    "                print(f'\\nTraining with {epochs} epochs, learning rate {learning_rate}, and metrics {metric.__name__}...\\n')\n",
    "\n",
    "                # Train the LSTM model with the specified parameters\n",
    "                y_pred_prob, y_pred_class = build_and_train_lstm(\n",
    "                    X_train, y_train, X_test, y_test,\n",
    "                    epochs=epochs,\n",
    "                    learning_rate=learning_rate,\n",
    "                    metric=metric\n",
    "                )\n",
    "\n",
    "                # Manually calculate custom accuracy (assuming the function takes y_true and y_pred as np arrays)\n",
    "                custom_acc = custom_accuracy(y_test, y_pred_class)\n",
    "                print(f'Custom accuracy: {custom_acc}')\n",
    "                \n",
    "                # Store results\n",
    "                results[(metric.__name__, learning_rate, epochs)] = {\n",
    "                    'custom_acc': custom_acc,\n",
    "                    'y_pred_prob': y_pred_prob,\n",
    "                    'y_pred_class': y_pred_class,\n",
    "                    'custom_accuracies_df': custom_acc\n",
    "                }\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6a939110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def plot_roc_curves(results, y_test, epochs_list):\\n    largest_epoch = max(epochs_list)\\n    models = [\\'Naive\\', \\'SV\\', \\'TI\\', \\'Full\\', \\'Hybrid\\']\\n\\n    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\\n    axes = axes.flatten()\\n    \\n    # Plot ROC curves for each model\\n    for idx, model in enumerate(models):\\n        y_pred_prob = results[model][largest_epoch][\\'y_pred_prob\\']\\n        \\n        fpr = dict()\\n        tpr = dict()\\n        roc_auc = dict()\\n        \\n        for i in range(y_pred_prob.shape[1]):\\n            fpr[i], tpr[i], _ = roc_curve(y_test == i - 1, y_pred_prob[:, i])\\n            roc_auc[i] = auc(fpr[i], tpr[i])\\n        \\n        # Plot ROC curves for each class\\n        for i in range(y_pred_prob.shape[1]):\\n            axes[idx].plot(fpr[i], tpr[i], label=f\\'Class {i-1} (area = {roc_auc[i]:0.2f})\\')\\n        \\n        # Plot ROC curve for the random classifier\\n        axes[idx].plot([0, 1], [0, 1], \\'k--\\')\\n        axes[idx].set_xlim([0.0, 1.0])\\n        axes[idx].set_ylim([0.0, 1.05])\\n        axes[idx].set_xlabel(\\'False Positive Rate\\')\\n        axes[idx].set_ylabel(\\'True Positive Rate\\')\\n        axes[idx].set_title(f\\'ROC Curve for {model} Model at Epoch {largest_epoch}\\')\\n        axes[idx].legend(loc=\"lower right\")\\n    \\n    # Hide the sixth subplot (bottom right corner) since we don\\'t need it\\n    axes[-1].axis(\\'off\\')\\n    \\n    plt.tight_layout()\\n    plt.show()'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_hybrid_predictions(y_pred_class_SV, y_pred_prob_SV, y_pred_class_TI, y_pred_prob_TI):\n",
    "    final_predictions = []\n",
    "    final_probabilities = []\n",
    "\n",
    "    for pred_SV, prob_SV, pred_TI, prob_TI in zip(y_pred_class_SV, y_pred_prob_SV, y_pred_class_TI, y_pred_prob_TI):\n",
    "        if pred_SV == 0 and pred_TI == 0:\n",
    "            # If either model predicts class-noact (0), the final decision is class-noact (0)\n",
    "            final_predictions.append(0)\n",
    "            final_probabilities.append(prob_SV)  # No active probabilities\n",
    "        elif pred_SV == pred_TI:\n",
    "            # If both models agree on the label, use that label\n",
    "            final_predictions.append(pred_SV)\n",
    "            final_probabilities.append(prob_SV)  \n",
    "        else:\n",
    "            # If predictions are different, compare the probabilities for the predicted classes\n",
    "            prob_SV_pred = prob_SV[np.argmax(prob_SV)]  # Probability for the class predicted by SV\n",
    "            prob_TI_pred = prob_TI[np.argmax(prob_TI)]  # Probability for the class predicted by TI\n",
    "            \n",
    "            if prob_SV_pred > prob_TI_pred:\n",
    "                final_predictions.append(pred_SV)\n",
    "                final_probabilities.append(prob_SV)\n",
    "            elif prob_SV_pred < prob_TI_pred:\n",
    "                final_predictions.append(pred_TI)\n",
    "                final_probabilities.append(prob_TI)\n",
    "            else:\n",
    "                # If probabilities are the same, choose the SV model's prediction\n",
    "                final_predictions.append(pred_SV)\n",
    "                final_probabilities.append(prob_SV)\n",
    "    \n",
    "    return np.array(final_predictions), np.array(final_probabilities)\n",
    "\n",
    "def generate_hybrid_predictions(metric_list,learn_rate_list, epochs_list, results_SV, results_TI, create_hybrid_predictions):\n",
    "    # Initialize a dictionary to store hybrid results\n",
    "    results_Hybrid = {}\n",
    "\n",
    "    # Iterate through each epoch to generate hybrid predictions\n",
    "    for metric in metric_list:\n",
    "        for learning_rate in learn_rate_list:\n",
    "            for epochs in epochs_list:\n",
    "                y_pred_class_SV = results_SV[(metric.__name__, learning_rate, epochs)]['y_pred_class']\n",
    "                y_pred_prob_SV = results_SV[(metric.__name__, learning_rate, epochs)]['y_pred_prob']\n",
    "                y_pred_class_TI = results_TI[(metric.__name__, learning_rate, epochs)]['y_pred_class']\n",
    "                y_pred_prob_TI = results_TI[(metric.__name__, learning_rate, epochs)]['y_pred_prob']\n",
    "\n",
    "        # Generate hybrid predictions and probabilities\n",
    "        hybrid_pred_class, hybrid_pred_prob = create_hybrid_predictions(\n",
    "            y_pred_class_SV, y_pred_prob_SV, y_pred_class_TI, y_pred_prob_TI\n",
    "        )\n",
    "\n",
    "        # Store hybrid results for this epoch\n",
    "        results_Hybrid[(metric.__name__, learning_rate, epochs)] = {\n",
    "            'y_pred_class': hybrid_pred_class,\n",
    "            'y_pred_prob': hybrid_pred_prob\n",
    "        }\n",
    "    \n",
    "    return results_Hybrid\n",
    "\n",
    "\n",
    "\n",
    "def create_trade_summary(y_true, results, metric_list,learn_rate_list, epochs_list, models):\n",
    "    summary_data = []\n",
    "\n",
    "    for metric in metric_list:\n",
    "        for learning_rate in learn_rate_list:\n",
    "            for epochs in epochs_list:\n",
    "                row_data = {('metric', 'learning_rate', 'epochs'): (metric.__name__, learning_rate, epochs)}\n",
    "\n",
    "                for model in models:\n",
    "                    y_pred_class = results[model][(metric.__name__, learning_rate, epochs)]['y_pred_class']\n",
    "                    acc = np.round(accuracy_score(y_true, y_pred_class),2)\n",
    "\n",
    "                    count = Counter(y_pred_class)\n",
    "                    pos_trade_count = count.get(1, 0)  # Positive trades count\n",
    "                    neg_trade_count = count.get(-1, 0)  # Negative trades count (if -1 is in the labels)\n",
    "                    no_action_count = count.get(0, 0)  # No-action count (if 0 is in the labels)\n",
    "                    total_transac = pos_trade_count + neg_trade_count \n",
    "                    total_transac_ptc = total_transac / (total_transac + no_action_count) \n",
    "                    pos_trade_ptc = f\"{(pos_trade_count / total_transac * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    neg_trade_ptc = f\"{(neg_trade_count / total_transac * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    total_transac_ptc = f\"{(total_transac_ptc * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    row_data[(model, 'Accuracy')] = acc\n",
    "                    row_data[(model, 'Pos_trade_pct')] = pos_trade_ptc\n",
    "                    row_data[(model, 'Neg_trade_pct')] = neg_trade_ptc\n",
    "                    #row_data[(model, 'Total_transac')] = total_transac\n",
    "                    row_data[(model, 'Total_transac_pct')] = total_transac_ptc\n",
    "        \n",
    "                summary_data.append(row_data)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.set_index(('metric', 'learning_rate', 'epochs'), inplace=True)\n",
    "    summary_df.columns = pd.MultiIndex.from_tuples(summary_df.columns)\n",
    "    \n",
    "    return summary_df\n",
    "    \n",
    "'''def plot_roc_curves(results, y_test, epochs_list):\n",
    "    largest_epoch = max(epochs_list)\n",
    "    models = ['Naive', 'SV', 'TI', 'Full', 'Hybrid']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot ROC curves for each model\n",
    "    for idx, model in enumerate(models):\n",
    "        y_pred_prob = results[model][largest_epoch]['y_pred_prob']\n",
    "        \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(y_pred_prob.shape[1]):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test == i - 1, y_pred_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot ROC curves for each class\n",
    "        for i in range(y_pred_prob.shape[1]):\n",
    "            axes[idx].plot(fpr[i], tpr[i], label=f'Class {i-1} (area = {roc_auc[i]:0.2f})')\n",
    "        \n",
    "        # Plot ROC curve for the random classifier\n",
    "        axes[idx].plot([0, 1], [0, 1], 'k--')\n",
    "        axes[idx].set_xlim([0.0, 1.0])\n",
    "        axes[idx].set_ylim([0.0, 1.05])\n",
    "        axes[idx].set_xlabel('False Positive Rate')\n",
    "        axes[idx].set_ylabel('True Positive Rate')\n",
    "        axes[idx].set_title(f'ROC Curve for {model} Model at Epoch {largest_epoch}')\n",
    "        axes[idx].legend(loc=\"lower right\")\n",
    "    \n",
    "    # Hide the sixth subplot (bottom right corner) since we don't need it\n",
    "    axes[-1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ffd2f",
   "metadata": {},
   "source": [
    "#### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5d1bc451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_f1_score...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 865s - 53ms/step - accuracy: 0.5129 - custom_f1_score: 0.3783 - loss: 1.1792 - val_accuracy: 0.2175 - val_custom_f1_score: 0.1383 - val_loss: 1.5811\n",
      "Epoch 2/30\n",
      "16400/16400 - 801s - 49ms/step - accuracy: 0.5252 - custom_f1_score: 0.3830 - loss: 1.0740 - val_accuracy: 0.3156 - val_custom_f1_score: 0.2090 - val_loss: 1.3713\n",
      "Epoch 3/30\n",
      "16400/16400 - 760s - 46ms/step - accuracy: 0.5237 - custom_f1_score: 0.3818 - loss: 1.0727 - val_accuracy: 0.4537 - val_custom_f1_score: 0.2169 - val_loss: 1.2982\n",
      "Epoch 4/30\n",
      "16400/16400 - 745s - 45ms/step - accuracy: 0.5254 - custom_f1_score: 0.3818 - loss: 1.0724 - val_accuracy: 0.2061 - val_custom_f1_score: 0.1310 - val_loss: 1.6505\n",
      "Epoch 5/30\n",
      "16400/16400 - 761s - 46ms/step - accuracy: 0.5249 - custom_f1_score: 0.3810 - loss: 1.0721 - val_accuracy: 0.2063 - val_custom_f1_score: 0.1086 - val_loss: 1.6804\n",
      "Epoch 6/30\n",
      "16400/16400 - 766s - 47ms/step - accuracy: 0.5269 - custom_f1_score: 0.3833 - loss: 1.0722 - val_accuracy: 0.2069 - val_custom_f1_score: 0.1410 - val_loss: 1.7399\n",
      "Epoch 7/30\n",
      "16400/16400 - 769s - 47ms/step - accuracy: 0.5236 - custom_f1_score: 0.3791 - loss: 1.0718 - val_accuracy: 0.4450 - val_custom_f1_score: 0.2525 - val_loss: 1.1477\n",
      "Epoch 8/30\n",
      "16400/16400 - 770s - 47ms/step - accuracy: 0.5246 - custom_f1_score: 0.3835 - loss: 1.0718 - val_accuracy: 0.2159 - val_custom_f1_score: 0.1280 - val_loss: 1.3679\n",
      "Epoch 9/30\n",
      "16400/16400 - 758s - 46ms/step - accuracy: 0.5238 - custom_f1_score: 0.3824 - loss: 1.0718 - val_accuracy: 0.4305 - val_custom_f1_score: 0.2354 - val_loss: 1.1515\n",
      "Epoch 10/30\n",
      "16400/16400 - 762s - 46ms/step - accuracy: 0.5230 - custom_f1_score: 0.3823 - loss: 1.0719 - val_accuracy: 0.3301 - val_custom_f1_score: 0.1845 - val_loss: 1.3545\n",
      "Epoch 11/30\n",
      "16400/16400 - 757s - 46ms/step - accuracy: 0.5222 - custom_f1_score: 0.3831 - loss: 1.0718 - val_accuracy: 0.4577 - val_custom_f1_score: 0.2399 - val_loss: 1.1684\n",
      "Epoch 12/30\n",
      "16400/16400 - 761s - 46ms/step - accuracy: 0.5231 - custom_f1_score: 0.3800 - loss: 1.0718 - val_accuracy: 0.2090 - val_custom_f1_score: 0.1359 - val_loss: 1.5743\n",
      "Epoch 13/30\n",
      "16400/16400 - 756s - 46ms/step - accuracy: 0.5233 - custom_f1_score: 0.3818 - loss: 1.0718 - val_accuracy: 0.4166 - val_custom_f1_score: 0.2380 - val_loss: 1.2558\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 7ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.45\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_precision...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 768s - 47ms/step - accuracy: 0.5096 - custom_precision: 0.3975 - loss: 1.1821 - val_accuracy: 0.2066 - val_custom_precision: 0.1155 - val_loss: 1.5220\n",
      "Epoch 2/30\n",
      "16400/16400 - 751s - 46ms/step - accuracy: 0.5248 - custom_precision: 0.3984 - loss: 1.0737 - val_accuracy: 0.2130 - val_custom_precision: 0.1054 - val_loss: 1.3994\n",
      "Epoch 3/30\n",
      "16400/16400 - 751s - 46ms/step - accuracy: 0.5236 - custom_precision: 0.4023 - loss: 1.0725 - val_accuracy: 0.2061 - val_custom_precision: 0.0733 - val_loss: 1.7102\n",
      "Epoch 4/30\n",
      "16400/16400 - 751s - 46ms/step - accuracy: 0.5229 - custom_precision: 0.4005 - loss: 1.0722 - val_accuracy: 0.2083 - val_custom_precision: 0.0695 - val_loss: 1.6325\n",
      "Epoch 5/30\n",
      "16400/16400 - 753s - 46ms/step - accuracy: 0.5224 - custom_precision: 0.3998 - loss: 1.0717 - val_accuracy: 0.2063 - val_custom_precision: 0.0688 - val_loss: 1.8561\n",
      "Epoch 6/30\n",
      "16400/16400 - 751s - 46ms/step - accuracy: 0.5237 - custom_precision: 0.3968 - loss: 1.0719 - val_accuracy: 0.4550 - val_custom_precision: 0.2478 - val_loss: 1.2371\n",
      "Epoch 7/30\n",
      "16400/16400 - 750s - 46ms/step - accuracy: 0.5234 - custom_precision: 0.3991 - loss: 1.0715 - val_accuracy: 0.3515 - val_custom_precision: 0.1933 - val_loss: 1.3110\n",
      "Epoch 8/30\n",
      "16400/16400 - 751s - 46ms/step - accuracy: 0.5221 - custom_precision: 0.3976 - loss: 1.0717 - val_accuracy: 0.2082 - val_custom_precision: 0.0824 - val_loss: 1.3734\n",
      "Epoch 9/30\n",
      "16400/16400 - 756s - 46ms/step - accuracy: 0.5230 - custom_precision: 0.3973 - loss: 1.0713 - val_accuracy: 0.2063 - val_custom_precision: 0.0688 - val_loss: 1.5715\n",
      "Epoch 10/30\n",
      "16400/16400 - 750s - 46ms/step - accuracy: 0.5218 - custom_precision: 0.4007 - loss: 1.0714 - val_accuracy: 0.2062 - val_custom_precision: 0.1079 - val_loss: 1.6328\n",
      "Epoch 11/30\n",
      "16400/16400 - 754s - 46ms/step - accuracy: 0.5217 - custom_precision: 0.3977 - loss: 1.0712 - val_accuracy: 0.2240 - val_custom_precision: 0.1225 - val_loss: 1.3637\n",
      "Epoch 12/30\n",
      "16400/16400 - 752s - 46ms/step - accuracy: 0.5220 - custom_precision: 0.3964 - loss: 1.0713 - val_accuracy: 0.2613 - val_custom_precision: 0.1400 - val_loss: 1.3219\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 7ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.46\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_recall...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 778s - 47ms/step - accuracy: 0.5132 - custom_recall: 0.4064 - loss: 1.1857 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.6827\n",
      "Epoch 2/30\n",
      "16400/16400 - 773s - 47ms/step - accuracy: 0.5243 - custom_recall: 0.4112 - loss: 1.0740 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.4779\n",
      "Epoch 3/30\n",
      "16400/16400 - 774s - 47ms/step - accuracy: 0.5242 - custom_recall: 0.4120 - loss: 1.0726 - val_accuracy: 0.2062 - val_custom_recall: 0.3215 - val_loss: 1.5563\n",
      "Epoch 4/30\n",
      "16400/16400 - 772s - 47ms/step - accuracy: 0.5228 - custom_recall: 0.4125 - loss: 1.0725 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.5296\n",
      "Epoch 5/30\n",
      "16400/16400 - 786s - 48ms/step - accuracy: 0.5245 - custom_recall: 0.4122 - loss: 1.0724 - val_accuracy: 0.2061 - val_custom_recall: 0.3223 - val_loss: 1.6350\n",
      "Epoch 6/30\n",
      "16400/16400 - 796s - 49ms/step - accuracy: 0.5226 - custom_recall: 0.4125 - loss: 1.0718 - val_accuracy: 0.2060 - val_custom_recall: 0.3216 - val_loss: 1.5428\n",
      "Epoch 7/30\n",
      "16400/16400 - 794s - 48ms/step - accuracy: 0.5232 - custom_recall: 0.4122 - loss: 1.0718 - val_accuracy: 0.4351 - val_custom_recall: 0.3427 - val_loss: 1.1547\n",
      "Epoch 8/30\n",
      "16400/16400 - 793s - 48ms/step - accuracy: 0.5218 - custom_recall: 0.4121 - loss: 1.0720 - val_accuracy: 0.4613 - val_custom_recall: 0.3416 - val_loss: 1.1936\n",
      "Epoch 9/30\n",
      "16400/16400 - 783s - 48ms/step - accuracy: 0.5203 - custom_recall: 0.4121 - loss: 1.0716 - val_accuracy: 0.2083 - val_custom_recall: 0.3233 - val_loss: 1.5414\n",
      "Epoch 10/30\n",
      "16400/16400 - 770s - 47ms/step - accuracy: 0.5216 - custom_recall: 0.4125 - loss: 1.0717 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.5880\n",
      "Epoch 11/30\n",
      "16400/16400 - 780s - 48ms/step - accuracy: 0.5221 - custom_recall: 0.4129 - loss: 1.0718 - val_accuracy: 0.2258 - val_custom_recall: 0.3259 - val_loss: 1.4696\n",
      "Epoch 12/30\n",
      "16400/16400 - 781s - 48ms/step - accuracy: 0.5222 - custom_recall: 0.4125 - loss: 1.0715 - val_accuracy: 0.2190 - val_custom_recall: 0.3249 - val_loss: 1.4935\n",
      "Epoch 13/30\n",
      "16400/16400 - 776s - 47ms/step - accuracy: 0.5216 - custom_recall: 0.4126 - loss: 1.0713 - val_accuracy: 0.4471 - val_custom_recall: 0.3420 - val_loss: 1.1485\n",
      "Epoch 14/30\n",
      "16400/16400 - 768s - 47ms/step - accuracy: 0.5229 - custom_recall: 0.4129 - loss: 1.0713 - val_accuracy: 0.2121 - val_custom_recall: 0.3230 - val_loss: 1.4670\n",
      "Epoch 15/30\n",
      "16400/16400 - 769s - 47ms/step - accuracy: 0.5218 - custom_recall: 0.4123 - loss: 1.0711 - val_accuracy: 0.3890 - val_custom_recall: 0.3405 - val_loss: 1.2500\n",
      "Epoch 16/30\n",
      "16400/16400 - 770s - 47ms/step - accuracy: 0.5222 - custom_recall: 0.4129 - loss: 1.0712 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.6090\n",
      "Epoch 17/30\n",
      "16400/16400 - 769s - 47ms/step - accuracy: 0.5218 - custom_recall: 0.4127 - loss: 1.0711 - val_accuracy: 0.3464 - val_custom_recall: 0.3378 - val_loss: 1.2985\n",
      "Epoch 18/30\n",
      "16400/16400 - 767s - 47ms/step - accuracy: 0.5211 - custom_recall: 0.4126 - loss: 1.0712 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.8626\n",
      "Epoch 19/30\n",
      "16400/16400 - 770s - 47ms/step - accuracy: 0.5208 - custom_recall: 0.4123 - loss: 1.0712 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.5273\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 7ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.45\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_f1_score...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 844s - 51ms/step - accuracy: 0.5292 - custom_f1_score: 0.3958 - loss: 1.1822 - val_accuracy: 0.2083 - val_custom_f1_score: 0.1093 - val_loss: 2.2174\n",
      "Epoch 2/30\n",
      "16400/16400 - 833s - 51ms/step - accuracy: 0.5452 - custom_f1_score: 0.4009 - loss: 1.0548 - val_accuracy: 0.2063 - val_custom_f1_score: 0.1086 - val_loss: 1.6956\n",
      "Epoch 3/30\n",
      "16400/16400 - 835s - 51ms/step - accuracy: 0.5457 - custom_f1_score: 0.4002 - loss: 1.0538 - val_accuracy: 0.5504 - val_custom_f1_score: 0.2669 - val_loss: 1.0274\n",
      "Epoch 4/30\n",
      "16400/16400 - 830s - 51ms/step - accuracy: 0.5462 - custom_f1_score: 0.3975 - loss: 1.0534 - val_accuracy: 0.2062 - val_custom_f1_score: 0.1112 - val_loss: 1.4145\n",
      "Epoch 5/30\n",
      "16400/16400 - 831s - 51ms/step - accuracy: 0.5467 - custom_f1_score: 0.4010 - loss: 1.0530 - val_accuracy: 0.5644 - val_custom_f1_score: 0.2615 - val_loss: 1.0463\n",
      "Epoch 6/30\n",
      "16400/16400 - 832s - 51ms/step - accuracy: 0.5458 - custom_f1_score: 0.3971 - loss: 1.0529 - val_accuracy: 0.2969 - val_custom_f1_score: 0.1649 - val_loss: 1.4083\n",
      "Epoch 7/30\n",
      "16400/16400 - 824s - 50ms/step - accuracy: 0.5457 - custom_f1_score: 0.3980 - loss: 1.0528 - val_accuracy: 0.5447 - val_custom_f1_score: 0.2647 - val_loss: 1.0284\n",
      "Epoch 8/30\n",
      "16400/16400 - 828s - 50ms/step - accuracy: 0.5464 - custom_f1_score: 0.3971 - loss: 1.0529 - val_accuracy: 0.3078 - val_custom_f1_score: 0.1797 - val_loss: 1.3262\n",
      "Epoch 9/30\n",
      "16400/16400 - 823s - 50ms/step - accuracy: 0.5465 - custom_f1_score: 0.4014 - loss: 1.0529 - val_accuracy: 0.3827 - val_custom_f1_score: 0.2017 - val_loss: 1.2790\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 7ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.55\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_precision...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 808s - 49ms/step - accuracy: 0.5250 - custom_precision: 0.4122 - loss: 1.1774 - val_accuracy: 0.2156 - val_custom_precision: 0.0913 - val_loss: 1.4856\n",
      "Epoch 2/30\n",
      "16400/16400 - 785s - 48ms/step - accuracy: 0.5452 - custom_precision: 0.4195 - loss: 1.0555 - val_accuracy: 0.4825 - val_custom_precision: 0.2545 - val_loss: 1.0966\n",
      "Epoch 3/30\n",
      "16400/16400 - 779s - 48ms/step - accuracy: 0.5451 - custom_precision: 0.4094 - loss: 1.0544 - val_accuracy: 0.2063 - val_custom_precision: 0.0689 - val_loss: 1.6547\n",
      "Epoch 4/30\n",
      "16400/16400 - 783s - 48ms/step - accuracy: 0.5452 - custom_precision: 0.4176 - loss: 1.0545 - val_accuracy: 0.3148 - val_custom_precision: 0.1537 - val_loss: 1.2970\n",
      "Epoch 5/30\n",
      "16400/16400 - 780s - 48ms/step - accuracy: 0.5440 - custom_precision: 0.4110 - loss: 1.0539 - val_accuracy: 0.4461 - val_custom_precision: 0.2506 - val_loss: 1.1495\n",
      "Epoch 6/30\n",
      "16400/16400 - 779s - 48ms/step - accuracy: 0.5459 - custom_precision: 0.4153 - loss: 1.0538 - val_accuracy: 0.4743 - val_custom_precision: 0.2453 - val_loss: 1.0995\n",
      "Epoch 7/30\n",
      "16400/16400 - 790s - 48ms/step - accuracy: 0.5449 - custom_precision: 0.4160 - loss: 1.0538 - val_accuracy: 0.4585 - val_custom_precision: 0.2596 - val_loss: 1.1365\n",
      "Epoch 8/30\n",
      "16400/16400 - 781s - 48ms/step - accuracy: 0.5440 - custom_precision: 0.4123 - loss: 1.0538 - val_accuracy: 0.2064 - val_custom_precision: 0.0836 - val_loss: 1.6030\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 7ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.48\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_recall...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 790s - 48ms/step - accuracy: 0.5340 - custom_recall: 0.4297 - loss: 1.1650 - val_accuracy: 0.2061 - val_custom_recall: 0.3220 - val_loss: 1.5983\n",
      "Epoch 2/30\n",
      "16400/16400 - 769s - 47ms/step - accuracy: 0.5472 - custom_recall: 0.4373 - loss: 1.0543 - val_accuracy: 0.3662 - val_custom_recall: 0.3360 - val_loss: 1.2277\n",
      "Epoch 3/30\n",
      "16400/16400 - 780s - 48ms/step - accuracy: 0.5471 - custom_recall: 0.4373 - loss: 1.0537 - val_accuracy: 0.2073 - val_custom_recall: 0.3200 - val_loss: 2.0112\n",
      "Epoch 4/30\n",
      "16400/16400 - 775s - 47ms/step - accuracy: 0.5454 - custom_recall: 0.4374 - loss: 1.0532 - val_accuracy: 0.3045 - val_custom_recall: 0.3327 - val_loss: 1.3821\n",
      "Epoch 5/30\n",
      "16400/16400 - 763s - 46ms/step - accuracy: 0.5459 - custom_recall: 0.4381 - loss: 1.0529 - val_accuracy: 0.2064 - val_custom_recall: 0.3216 - val_loss: 1.6650\n",
      "Epoch 6/30\n",
      "16400/16400 - 771s - 47ms/step - accuracy: 0.5462 - custom_recall: 0.4377 - loss: 1.0527 - val_accuracy: 0.5362 - val_custom_recall: 0.3482 - val_loss: 1.0751\n",
      "Epoch 7/30\n",
      "16400/16400 - 764s - 47ms/step - accuracy: 0.5459 - custom_recall: 0.4372 - loss: 1.0527 - val_accuracy: 0.2102 - val_custom_recall: 0.3238 - val_loss: 1.5296\n",
      "Epoch 8/30\n",
      "16400/16400 - 755s - 46ms/step - accuracy: 0.5451 - custom_recall: 0.4372 - loss: 1.0525 - val_accuracy: 0.3612 - val_custom_recall: 0.3395 - val_loss: 1.2179\n",
      "Epoch 9/30\n",
      "16400/16400 - 756s - 46ms/step - accuracy: 0.5456 - custom_recall: 0.4376 - loss: 1.0525 - val_accuracy: 0.3461 - val_custom_recall: 0.3385 - val_loss: 1.2265\n",
      "Epoch 10/30\n",
      "16400/16400 - 753s - 46ms/step - accuracy: 0.5456 - custom_recall: 0.4370 - loss: 1.0524 - val_accuracy: 0.5712 - val_custom_recall: 0.3491 - val_loss: 1.0086\n",
      "Epoch 11/30\n",
      "16400/16400 - 762s - 46ms/step - accuracy: 0.5459 - custom_recall: 0.4381 - loss: 1.0525 - val_accuracy: 0.2529 - val_custom_recall: 0.3298 - val_loss: 1.4001\n",
      "Epoch 12/30\n",
      "16400/16400 - 777s - 47ms/step - accuracy: 0.5447 - custom_recall: 0.4372 - loss: 1.0528 - val_accuracy: 0.5528 - val_custom_recall: 0.3504 - val_loss: 1.0274\n",
      "Epoch 13/30\n",
      "16400/16400 - 857s - 52ms/step - accuracy: 0.5452 - custom_recall: 0.4375 - loss: 1.0524 - val_accuracy: 0.2063 - val_custom_recall: 0.3216 - val_loss: 1.5012\n",
      "Epoch 14/30\n",
      "16400/16400 - 913s - 56ms/step - accuracy: 0.5457 - custom_recall: 0.4379 - loss: 1.0525 - val_accuracy: 0.4753 - val_custom_recall: 0.3484 - val_loss: 1.0878\n",
      "Epoch 15/30\n",
      "16400/16400 - 857s - 52ms/step - accuracy: 0.5452 - custom_recall: 0.4376 - loss: 1.0524 - val_accuracy: 0.4508 - val_custom_recall: 0.3399 - val_loss: 1.1646\n",
      "Epoch 16/30\n",
      "16400/16400 - 839s - 51ms/step - accuracy: 0.5463 - custom_recall: 0.4375 - loss: 1.0524 - val_accuracy: 0.4532 - val_custom_recall: 0.3392 - val_loss: 1.1702\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 8ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.57\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_f1_score...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 834s - 51ms/step - accuracy: 0.5455 - custom_f1_score: 0.4158 - loss: 1.1365 - val_accuracy: 0.6001 - val_custom_f1_score: 0.2864 - val_loss: 0.9065\n",
      "Epoch 2/30\n",
      "16400/16400 - 821s - 50ms/step - accuracy: 0.5494 - custom_f1_score: 0.4129 - loss: 1.0327 - val_accuracy: 0.5914 - val_custom_f1_score: 0.2843 - val_loss: 0.9071\n",
      "Epoch 3/30\n",
      "16400/16400 - 835s - 51ms/step - accuracy: 0.5480 - custom_f1_score: 0.4125 - loss: 1.0313 - val_accuracy: 0.5922 - val_custom_f1_score: 0.2500 - val_loss: 1.4118\n",
      "Epoch 4/30\n",
      "16400/16400 - 850s - 52ms/step - accuracy: 0.5485 - custom_f1_score: 0.4105 - loss: 1.0310 - val_accuracy: 0.3506 - val_custom_f1_score: 0.1765 - val_loss: 1.2335\n",
      "Epoch 5/30\n",
      "16400/16400 - 847s - 52ms/step - accuracy: 0.5479 - custom_f1_score: 0.4085 - loss: 1.0304 - val_accuracy: 0.2488 - val_custom_f1_score: 0.1297 - val_loss: 1.2768\n",
      "Epoch 6/30\n",
      "16400/16400 - 926s - 56ms/step - accuracy: 0.5480 - custom_f1_score: 0.4130 - loss: 1.0303 - val_accuracy: 0.6019 - val_custom_f1_score: 0.2701 - val_loss: 1.0135\n",
      "Epoch 7/30\n",
      "16400/16400 - 937s - 57ms/step - accuracy: 0.5492 - custom_f1_score: 0.4123 - loss: 1.0299 - val_accuracy: 0.2396 - val_custom_f1_score: 0.1264 - val_loss: 1.3425\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 11ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0       0.6\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_precision...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 1029s - 63ms/step - accuracy: 0.5420 - custom_precision: 0.4368 - loss: 1.1710 - val_accuracy: 0.5863 - val_custom_precision: 0.2965 - val_loss: 0.8924\n",
      "Epoch 2/30\n",
      "16400/16400 - 1006s - 61ms/step - accuracy: 0.5495 - custom_precision: 0.4362 - loss: 1.0329 - val_accuracy: 0.6029 - val_custom_precision: 0.2467 - val_loss: 0.8989\n",
      "Epoch 3/30\n",
      "16400/16400 - 922s - 56ms/step - accuracy: 0.5489 - custom_precision: 0.4331 - loss: 1.0311 - val_accuracy: 0.4656 - val_custom_precision: 0.2239 - val_loss: 1.0707\n",
      "Epoch 4/30\n",
      "16400/16400 - 802s - 49ms/step - accuracy: 0.5489 - custom_precision: 0.4339 - loss: 1.0307 - val_accuracy: 0.4813 - val_custom_precision: 0.2537 - val_loss: 1.0509\n",
      "Epoch 5/30\n",
      "16400/16400 - 796s - 49ms/step - accuracy: 0.5489 - custom_precision: 0.4334 - loss: 1.0305 - val_accuracy: 0.2063 - val_custom_precision: 0.0688 - val_loss: 1.3615\n",
      "Epoch 6/30\n",
      "16400/16400 - 783s - 48ms/step - accuracy: 0.5488 - custom_precision: 0.4351 - loss: 1.0301 - val_accuracy: 0.5962 - val_custom_precision: 0.2528 - val_loss: 0.8937\n",
      "Epoch 7/30\n",
      "16400/16400 - 805s - 49ms/step - accuracy: 0.5489 - custom_precision: 0.4326 - loss: 1.0298 - val_accuracy: 0.2609 - val_custom_precision: 0.1163 - val_loss: 1.2820\n",
      "\u001b[1m42378/42378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 9ms/step\n",
      "Custom accuracy:    Accuracy\n",
      "0      0.59\n",
      "\n",
      "Training with 30 epochs, learning rate 0.001, and metrics custom_recall...\n",
      "\n",
      "Epoch 1/30\n",
      "16400/16400 - 898s - 55ms/step - accuracy: 0.5441 - custom_recall: 0.4517 - loss: 1.1445 - val_accuracy: 0.2550 - val_custom_recall: 0.3309 - val_loss: 1.2327\n",
      "Epoch 2/30\n",
      "16400/16400 - 878s - 54ms/step - accuracy: 0.5486 - custom_recall: 0.4544 - loss: 1.0328 - val_accuracy: 0.5043 - val_custom_recall: 0.3481 - val_loss: 1.0291\n",
      "Epoch 3/30\n",
      "16400/16400 - 893s - 54ms/step - accuracy: 0.5485 - custom_recall: 0.4550 - loss: 1.0313 - val_accuracy: 0.2287 - val_custom_recall: 0.3280 - val_loss: 1.3295\n",
      "Epoch 4/30\n",
      "16400/16400 - 892s - 54ms/step - accuracy: 0.5481 - custom_recall: 0.4547 - loss: 1.0309 - val_accuracy: 0.5771 - val_custom_recall: 0.3515 - val_loss: 0.9249\n",
      "Epoch 5/30\n",
      "16400/16400 - 914s - 56ms/step - accuracy: 0.5490 - custom_recall: 0.4548 - loss: 1.0306 - val_accuracy: 0.2097 - val_custom_recall: 0.3229 - val_loss: 1.4252\n",
      "Epoch 6/30\n",
      "16400/16400 - 936s - 57ms/step - accuracy: 0.5472 - custom_recall: 0.4541 - loss: 1.0305 - val_accuracy: 0.2071 - val_custom_recall: 0.3244 - val_loss: 1.5734\n",
      "Epoch 7/30\n",
      "16400/16400 - 1152s - 70ms/step - accuracy: 0.5492 - custom_recall: 0.4542 - loss: 1.0300 - val_accuracy: 0.6036 - val_custom_recall: 0.3458 - val_loss: 0.8941\n",
      "Epoch 8/30\n",
      "16400/16400 - 847s - 52ms/step - accuracy: 0.5495 - custom_recall: 0.4549 - loss: 1.0297 - val_accuracy: 0.5990 - val_custom_recall: 0.3488 - val_loss: 0.9044\n",
      "Epoch 9/30\n",
      "16400/16400 - 987s - 60ms/step - accuracy: 0.5486 - custom_recall: 0.4546 - loss: 1.0297 - val_accuracy: 0.5996 - val_custom_recall: 0.3475 - val_loss: 0.9983\n",
      "Epoch 10/30\n",
      "16400/16400 - 979s - 60ms/step - accuracy: 0.5483 - custom_recall: 0.4543 - loss: 1.0298 - val_accuracy: 0.5047 - val_custom_recall: 0.3492 - val_loss: 1.0140\n",
      "Epoch 11/30\n",
      "16400/16400 - 1073s - 65ms/step - accuracy: 0.5490 - custom_recall: 0.4544 - loss: 1.0297 - val_accuracy: 0.5987 - val_custom_recall: 0.3419 - val_loss: 1.2003\n",
      "Epoch 12/30\n",
      "16400/16400 - 871s - 53ms/step - accuracy: 0.5484 - custom_recall: 0.4549 - loss: 1.0295 - val_accuracy: 0.6023 - val_custom_recall: 0.3473 - val_loss: 0.9664\n",
      "Epoch 13/30\n",
      "16400/16400 - 846s - 52ms/step - accuracy: 0.5481 - custom_recall: 0.4536 - loss: 1.0296 - val_accuracy: 0.6026 - val_custom_recall: 0.3464 - val_loss: 0.8901\n",
      "Epoch 14/30\n"
     ]
    }
   ],
   "source": [
    "# Define the epochs list\n",
    "epochs_list = [30]\n",
    "learn_rate_list = [0.001]\n",
    "metric_list = [custom_f1_score, custom_precision, custom_recall]\n",
    "\n",
    "\n",
    "results_Naive = evaluate_lstm_model(X_train_Naive, y_train, X_test_Naive, y_test, epochs_list=epochs_list,metric_list=metric_list,learning_rate_list=learn_rate_list)\n",
    "results_SV = evaluate_lstm_model(X_train_SV, y_train, X_test_SV, y_test, epochs_list=epochs_list,metric_list=metric_list,learning_rate_list=learn_rate_list)\n",
    "results_TI = evaluate_lstm_model(X_train_TI, y_train, X_test_TI, y_test, epochs_list=epochs_list,metric_list=metric_list,learning_rate_list=learn_rate_list)\n",
    "results_Full = evaluate_lstm_model(X_train, y_train, X_test, y_test, epochs_list=epochs_list,metric_list=metric_list,learning_rate_list=learn_rate_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a862a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name3 = f'quantile_upper_{quantile_upper}_{accuracy_metric}_{date(2024, 8, 19)}_{target_used}_min_data_grid_search'\n",
    "with open(f'results_Naive_{run_name3}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Naive, file)\n",
    "\n",
    "with open(f'results_SV_{run_name3}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_SV, file)\n",
    "\n",
    "with open(f'results_TI_{run_name3}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_TI, file)\n",
    "\n",
    "with open(f'results_Full_{run_name3}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Full, file)\n",
    "\n",
    "# Load the saved results from the pickle files\n",
    "with open(f'results_Naive_{run_name3}.pkl', 'rb') as file:\n",
    "    results_Naive_min = pickle.load(file)\n",
    "\n",
    "with open(f'results_SV_{run_name3}.pkl', 'rb') as file:\n",
    "    results_SV_min = pickle.load(file)\n",
    "\n",
    "with open(f'results_TI_{run_name3}.pkl', 'rb') as file:\n",
    "    results_TI_min = pickle.load(file)\n",
    "\n",
    "with open(f'results_Full_{run_name3}.pkl', 'rb') as file:\n",
    "    results_Full_min = pickle.load(file)\n",
    "\n",
    "epochs_list = [30]\n",
    "models = ['Naive','SV', 'TI', 'Full', 'Hybrid'] \n",
    "results_min = {\n",
    "    'Naive': results_Naive_min,\n",
    "    'SV': results_SV_min,\n",
    "    'TI': results_TI_min,\n",
    "    'Full': results_Full_min,\n",
    "    'Hybrid': generate_hybrid_predictions(metric_list,learn_rate_list, epochs_list,  results_SV_min, results_TI_min, create_hybrid_predictions)\n",
    "}\n",
    "\n",
    "trade_summary_min = create_trade_summary(y_test, results_min, metric_list,learn_rate_list, epochs_list, models)\n",
    "trade_summary_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trade_summary(y_true, results, metric_list,learn_rate_list, epochs_list, models):\n",
    "    summary_data = []\n",
    "\n",
    "    for metric in metric_list:\n",
    "        for learning_rate in learn_rate_list:\n",
    "            for epochs in epochs_list:\n",
    "                row_data = {('metric', 'learning_rate', 'epochs'): (metric.__name__, learning_rate, epochs)}\n",
    "\n",
    "                for model in models:\n",
    "                    y_pred_class = results[model][(metric.__name__, learning_rate, epochs)]['y_pred_class']\n",
    "                    acc = np.round(accuracy_score(y_true, y_pred_class),2)\n",
    "\n",
    "                    count = Counter(y_pred_class)\n",
    "                    pos_trade_count = count.get(1, 0)  # Positive trades count\n",
    "                    neg_trade_count = count.get(-1, 0)  # Negative trades count (if -1 is in the labels)\n",
    "                    no_action_count = count.get(0, 0)  # No-action count (if 0 is in the labels)\n",
    "                    total_transac = pos_trade_count + neg_trade_count \n",
    "                    total_transac_ptc = total_transac / (total_transac + no_action_count) \n",
    "                    pos_trade_ptc = f\"{(pos_trade_count / total_transac * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    neg_trade_ptc = f\"{(neg_trade_count / total_transac * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    total_transac_ptc = f\"{(total_transac_ptc * 100):.0f}%\" if total_transac > 0 else \"0.00%\"\n",
    "                    row_data[(model, 'Accuracy')] = acc\n",
    "                    row_data[(model, 'Pos_trade_pct')] = pos_trade_ptc\n",
    "                    row_data[(model, 'Neg_trade_pct')] = neg_trade_ptc\n",
    "                    #row_data[(model, 'Total_transac')] = total_transac\n",
    "                    row_data[(model, 'Total_transac_pct')] = total_transac_ptc\n",
    "        \n",
    "                summary_data.append(row_data)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.set_index(('metric', 'learning_rate', 'epochs'), inplace=True)\n",
    "    summary_df.columns = pd.MultiIndex.from_tuples(summary_df.columns)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be666863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33655917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ce0571c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Naive</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SV</th>\n",
       "      <th colspan=\"4\" halign=\"left\">TI</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Full</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Hybrid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(metric, learning_rate, epochs)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(custom_f1_score, 0.001, 30)</th>\n",
       "      <td>0.60</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>4%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>99%</td>\n",
       "      <td>1%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.27</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>81%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(custom_precision, 0.001, 30)</th>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.55</td>\n",
       "      <td>99%</td>\n",
       "      <td>1%</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(custom_recall, 0.001, 30)</th>\n",
       "      <td>0.20</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>98%</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>99%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.62</td>\n",
       "      <td>6%</td>\n",
       "      <td>94%</td>\n",
       "      <td>5%</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Naive                              \\\n",
       "                                Accuracy Pos_trade_pct Neg_trade_pct   \n",
       "(metric, learning_rate, epochs)                                        \n",
       "(custom_f1_score, 0.001, 30)        0.60          100%            0%   \n",
       "(custom_precision, 0.001, 30)       0.19          100%            0%   \n",
       "(custom_recall, 0.001, 30)          0.20          100%            0%   \n",
       "\n",
       "                                                        SV                \\\n",
       "                                Total_transac_pct Accuracy Pos_trade_pct   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)                   4%     0.19          100%   \n",
       "(custom_precision, 0.001, 30)                100%     0.19          100%   \n",
       "(custom_recall, 0.001, 30)                    98%     0.20          100%   \n",
       "\n",
       "                                                                      TI  \\\n",
       "                                Neg_trade_pct Total_transac_pct Accuracy   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)               0%              100%     0.19   \n",
       "(custom_precision, 0.001, 30)              0%              100%     0.55   \n",
       "(custom_recall, 0.001, 30)                 0%               99%     0.19   \n",
       "\n",
       "                                                                               \\\n",
       "                                Pos_trade_pct Neg_trade_pct Total_transac_pct   \n",
       "(metric, learning_rate, epochs)                                                 \n",
       "(custom_f1_score, 0.001, 30)              99%            1%              100%   \n",
       "(custom_precision, 0.001, 30)             99%            1%               33%   \n",
       "(custom_recall, 0.001, 30)               100%            0%              100%   \n",
       "\n",
       "                                    Full                              \\\n",
       "                                Accuracy Pos_trade_pct Neg_trade_pct   \n",
       "(metric, learning_rate, epochs)                                        \n",
       "(custom_f1_score, 0.001, 30)        0.27          100%            0%   \n",
       "(custom_precision, 0.001, 30)       0.19          100%            0%   \n",
       "(custom_recall, 0.001, 30)          0.62            6%           94%   \n",
       "\n",
       "                                                    Hybrid                \\\n",
       "                                Total_transac_pct Accuracy Pos_trade_pct   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)                  81%     0.19          100%   \n",
       "(custom_precision, 0.001, 30)                100%     0.19          100%   \n",
       "(custom_recall, 0.001, 30)                     5%     0.19          100%   \n",
       "\n",
       "                                                                 \n",
       "                                Neg_trade_pct Total_transac_pct  \n",
       "(metric, learning_rate, epochs)                                  \n",
       "(custom_f1_score, 0.001, 30)               0%              100%  \n",
       "(custom_precision, 0.001, 30)              0%              100%  \n",
       "(custom_recall, 0.001, 30)                 0%              100%  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name2 = f'quantile_upper_{quantile_upper}_{accuracy_metric}_{date(2024, 8, 19)}_{target_used}_hourly_data_grid_search'\n",
    "with open(f'results_Naive_{run_name2}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Naive, file)\n",
    "\n",
    "with open(f'results_SV_{run_name2}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_SV, file)\n",
    "\n",
    "with open(f'results_TI_{run_name2}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_TI, file)\n",
    "\n",
    "with open(f'results_Full_{run_name2}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Full, file)\n",
    "\n",
    "# Load the saved results from the pickle files\n",
    "with open(f'results_Naive_{run_name2}.pkl', 'rb') as file:\n",
    "    results_Naive_day = pickle.load(file)\n",
    "\n",
    "with open(f'results_SV_{run_name2}.pkl', 'rb') as file:\n",
    "    results_SV_day = pickle.load(file)\n",
    "\n",
    "with open(f'results_TI_{run_name2}.pkl', 'rb') as file:\n",
    "    results_TI_day = pickle.load(file)\n",
    "\n",
    "with open(f'results_Full_{run_name2}.pkl', 'rb') as file:\n",
    "    results_Full_day = pickle.load(file)\n",
    "\n",
    "epochs_list = [30]\n",
    "models = ['Naive','SV', 'TI', 'Full', 'Hybrid'] \n",
    "results_day = {\n",
    "    'Naive': results_Naive_day,\n",
    "    'SV': results_SV_day,\n",
    "    'TI': results_TI_day,\n",
    "    'Full': results_Full_day,\n",
    "    'Hybrid': generate_hybrid_predictions(metric_list,learn_rate_list, epochs_list,  results_SV_day, results_TI_day, create_hybrid_predictions)\n",
    "}\n",
    "\n",
    "trade_summary_day = create_trade_summary(y_test, results_day, metric_list,learn_rate_list, epochs_list, models)\n",
    "trade_summary_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9767795",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_summary_day.to_csv('trade_summary_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "754746e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACZoAAAHiCAYAAABrtOuKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeSUlEQVR4nO3dfaCX8+E//mfpbrnJ3OuLhm2EGZawuRmb8WWbMR+ZkYqOSklFcjc32YfVpFGhmYUwY/iYj9ka811uIxZtfBjlZlRKN6Pc1Hn//vDrfM7p5qrodDqXx+MfzrvrXO9X7+f7db2u6+p53qdJpVKpBAAAAAAAAAAAAJajaUMPAAAAAAAAAAAAgLWbohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUEjRDAAAAAAAAAAAgEKKZgAAAAAAAAAAABRSNAMAAAAAAAAAAKCQohkAAAAAAAAAAACFFM0AAAAAAAAAAAAopGgGAAAAAAAAAABAIUUzAAAAAAAAAAAACimaAQAAAAAAAAAAUKhZQw+ANee1117LzJkzG3oYrEYffPBBWrZs2dDDYDWRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNcNtlkk2yzzTYr3E7R7DPitddeS/v27TN//vyGHgqr0TrrrJNFixY19DBYTeRZLvIsF3mWj0zLRZ7lIs9ykWf5yLRc5Fku8iwXeZaPTMtFnuUiz3KRZ/nItFzkWS7yLJfWrVvn+eefX2HZTNHsM2LmzJmZP39+xo4dm/bt2zf0cFgN7rvvvpx//vkyLQl5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNc5Fk+Mi0XeZaLPMvl+eefz/HHH5+ZM2cqmlFX+/bts8ceezT0MFgNnn/++SQyLQt5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNc5Fk+Mi0XeZaLPD+7mjb0AAAAAAAAAAAAAFi7KZoBAAAAAAAAAABQSNGMejV48OAkSe/evfPQQw9lr732SpL8/Oc/z9SpU5fa/rLLLlvhPnv37r3UY1OnTs3Pf/7zJMnIkSNzxhlnfOIxVyqVld72wgsvzMyZM3PxxRd/4udb26zpzMaMGZNOnTrlyCOPzOTJk1dqjLXzXmx5uT311FMZM2bMSu13WRZnnHz893jkkUfywAMPfOL9rUkNleXytisi06Wtyfwuuuii9OjRIx06dEiXLl3yq1/9aoXft7zHl3xsVY6pq8viMYwZMyZPPfVULrnkklRXV6/xcdSH2u+LSZMmpVOnTunVq1fGjx+frl271mxXVVWVcePG5Y477lhqH4tfn0WLFuVLX/pS3nrrrU80llXNdm2eb/VpdWZ24IEHpqqqapXOc1ZlTq7qsXt531/G86Nk9Wb5xS9+Mc8991xmzpyZCy+8cJXGIdNPZnXld9ttt6VHjx7ZZZdd0qNHj0yfPr3mz2ufY9T20EMPLbW/JbdtiPVy8TqZfPx3e/311/PrX/96jY9jTar9Pjj99NNz4IEH5oc//GGGDBlS835f1rypneH555+/1Hnryvoka2ftcX8WfdrMLrzwwpx88sk54ogjMm3atJV6zmXN2eVld8cdd+Shhx5ahb9RXYvHvvh66JZbbsk///nPT7y/tdnqyPKss85a7nZFZPrpfZr8brzxxjpr5913313z58u6F7DYkvtblfsG9alM50crsuR9ie985zvp0aNH/vGPf9TZrvY8nTlzpnu3Dag+MnPvtuHUZ56L97sq5LpqVnd+7t+u3ZbMe/G557Lu5S/v/KdSqSx1j7/oPKv2Nf2JJ56Y22677RON/ZNcpy5YsCBDhw79RM+3tmjIzKqqqnLqqafm6KOPzoIFC1ZqvLXzXvzcy7O8f0NaWYvHvvh1GT58eObNm/eJ91ffGjLLbt26ZeTIkcvdrohMP9ZQ+T355JN1rlPHjx9f8+fLuoew5H6Ltl3T62rt12VN3ktsVu/PwGfWxIkT0759+yRJ69atkyRbbbVVxo0bV7PNPffck/Hjx2ejjTbK2WefnTfeeCNXX3119t9//2yxxRYZMWJEvv3tb+fOO+/MO++8kyuuuKJmX7U1bdo0rVq1SpK89NJLadKkSRYtWpSXXnopQ4YMyec///kMHTo0/fr1S8uWLXPkkUfm5ptvzogRI3LhhRemd+/e+fGPf5xvfetb6dSpU0aPHp1//etf+cUvfpFnn302N910U7baaqtss802+cpXvpK2bdtmzJgxadWqVZo2bZq2bdvmf/7nf7LDDjusgVe2/jRUZmeeeWY++uijjB8/Ptdcc02S5KCDDsr666+fO+64I9ttt13NDeXk4wvVP/3pT9lpp51y4403Zo899sihhx6a22+/Pa+//np+8pOfZN68eRk+fHhatGiRr3/963nkkUfqjGnDDTes2d93vvOdHHrooXnnnXdyySWX5MILL8x7772Xb37zm3nqqacyZMiQnH766WndunW+/vWv56yzzsq3vvWt1f76r04NlWWlUsn//M//1PzZmDFj8txzz6Vp06YZMmRIqqqqstlmm2XKlCm55ZZbaraTaV1rOr+NN944F1xwQc3x8KabbsoZZ5yRDTbYIIcddlgmTJiQW265JVtttVX++7//O9XV1cu8kHzqqadqtv3rX/+a7bbbLoccckjuuuuuvPnmmznppJPy/PPPZ9KkSfnggw/Sq1evPP3005k4cWJ23nnnHHroobn22muXefz9yU9+UvM8Dz30UEaPHp3tt98+++67b3bfffcMGjQoG2+8cY455phMmDAho0aNyoYbbphmzZpl7733zrhx43LIIYes7qjWqCXfF+PGjct5552Xr3zlK0k+fv0nT56cbbfdNq1atcrnPve5ZV6oLn4fPPTQQ+nZs2duv/32nHbaaXXmyQYbbFDz2u+///6ZOXNmjj766PTu3TsdOnTIxIkTc+ihh2bmzJmZNGlSdtxxx1RVVaVv37416+xvfvOb/OIXv8hZZ52VCy64YK2db/VpdWe28847Z8SIETnhhBPywAMP5I477shHH32Uq6++Or179856662XE044IbvttluSZOHChZkwYUIuvPDCdOzYMWPHjs33vve9rLvuunWOH2eeeWaaNWuWl19+OcnHJYp///vf2WWXXXLyySfXjGPMmDGZOHFiWrRokRNOOCGtWrWqOc/q1KlTzfwv2/lRsvqz3G+//fLLX/6y5tj29ttv55JLLsmCBQty0kknZfbs2fmv//qvvPPOO+nZs2e++c1vJpHpJ7U68+vUqVM6deqU3r1759xzz83ZZ5+dSqWSc845p845xujRo2vWvmVZvO0PfvCDXHzxxTnyyCPTvn37OuvsIYcckv/7f/9vpk2blosuuignnXRSNt988/Tt2zd/+ctflnv83WeffWqep1OnTunYsWNeffXV/OIXv8ioUaPy8ssvZ4899shTTz2VRx99NK1bt07r1q2z9dZb5+9//3s9JLB2WPJ9MGTIkIwZMya77LJLOnToUHMjZlnnS82aNUuLFi1SqVTy3nvvZc6cOUmS8ePH16yXAwcOTO/evbPRRhvlpJNOylVXXZURI0akd+/eGTFiRPbaa6/88Ic/zKGHHppbb701s2bNytVXX50777wz/+///b/ssMMOmTdvXk4++eRMnTo1L730Us1YmjRpkrlz56ZNmzZr5sVaS6yOzJKPfyBj3LhxmThxYu688840bdo0Xbt2zT//+c+a89Cqqqqa7118Ttu2bdtcdNFFy7xP8Nhjj+Xuu+/OO++8k169euWee+7JX//61/z73//OyJEj06zZ/95u69ixY80/6A4YMKBmvn7ve9+rOaZ369YtrVq1yhFHHJGhQ4eucgl5bbe6spw+fXreeeedmj8bNmxY3njjjWy22Wbp06dPevToke222y7Tp0+vubeQyPTT+rT5bbjhhrnmmmtqjofnnntuxo8fn+233z6bbbZZzb2AhQsX1jmfWdLK3De48cYb06xZs7zyyiu59NJLM3bs2Lzxxhv5xje+kS9/+cvLPf726dOn5nk+K+dHK7Ks+xJVVVU5+uij89BDD+Uf//hHzTXi0UcfXed73bttGPWZmXu3a1595un+bf2rj/zcv117LSvv2iqVSvr27Vtzn/TEE0/MuHHj8tZbb2WXXXbJtttum9GjR+d73/te3njjjSRZ6r7OsvbbokWLNGvWLO+++2623nrrPPLII+nUqVNuv/32mnOcTp061bzuAwcOzEUXXVRznXrGGWekR48ey7wfMXLkyJp7B3/729/yn//5n7nrrrvyf/7P/0nr1q3zuc99LjNmzKjHV7V+NXRmLVq0yIgRI3LppZfmb3/7W375y1/W3Fu65557as5fax8fat/D6dq16zLvL9x444157rnnMnny5Bx99NF1ju+1jwdTp05Njx498s1vfjNbbLFFjj322Jr7GT/84Q8zYcKE/Od//mf233//tGjRIt/97ndz66235pRTTlmtOawODZ1l69at8+yzz2bhwoU1f1b7Puyhhx6aQYMGZauttkqrVq3qXBfKtGHza968ec116lVXXZU+ffrktttuy0EHHZRXXnml5h7CSy+9VOce7JJW5n7DwIEDs+OOO2bSpEm59tprc9FFF+WDDz7IYYcdlubNmy/3+Hv88cfXPM/i987MmTNz9tln55VXXqlZf3faaaeac7Q1eS/RJ5pRbyZOnJiddtopSTJkyJAkyTHHHJPbb7+9Zpvq6uo0b968TnniiCOOyD333JP//u//zne/+92MGTMm66+/ftZbb728+OKLNfuqbZtttknv3r3zr3/9K5tuumn23XffPPjgg/nVr36VK6+8Mpdffnn+/ve/Z4cddsiQIUPq/OPLYltssUUGDhyY5s2b54MPPsiiRYvy8MMP59Zbb821116bn/zkJ/mP//iP3Hnnnbnlllty3HHHZdCgQdloo42y88475+mnn17dL+Ea1xCZJR/fHB4zZkx22mmn7LrrrhkxYkTGjRuXGTNmLPUPoknSoUOHfOc738lhhx2Wli1bZuDAgdluu+3y4YcfZr311ssf/vCH3HTTTbn66qtz1FFHJclSY6ptiy22SP/+/dO0adO8+uqref/99zN06NAcfvjh6dChQwYOHJi2bdtmyJAhadKkSd5///3V8GrXr4bKskePHnVu6N98881Zf/31M3369Dz77LPp2LFjfvrTn6ZJkyZ19iHTuhoqv8Veeuml/PznP8+sWbOy6667pmPHjjnuuOPStGnTVCqVPPHEE3nvvfeW2leHDh1qtl20aFH69euXXXbZJdXV1dlss81qWv2HHXZY+vfvnwcffDBvv/12zfc0a9ZsucffJX3729/O4MGDc++99+a2227LGWeckaFDh2bPPfdMx44d06tXrxx33HHZbbfdSnuM7tq1a2644YZ07949zz//fP7jP/4jv/vd73LPPffke9/7Xvbdd998//vfX2o/i98H9957b3r16pV//OMfmTt3bp15UvTaJ8lRRx2Vww8/PAsXLsy6666b+++/P88991yddXbzzTfP66+/nurq6pp/kFob51t9Wt2Z/eMf/8ipp56ab37zm7nzzjtz9dVX59BDD81f//rXfPDBBznqqKNqSmbJx/+w17Fjx1x44YVp3bp1Dj744PzoRz+qc/yYM2dOmjdvnksvvTRt2rTJ5MmTM3ny5Gy44YZ56aWXlhrLkUceWfOPdrXPszp27Fgzl8t2fpSs/izXXXfdbL755nnllVeSJLfddluaNm2azTffPJMmTcrvf//7XH311UvdRJfpJ7O681vst7/9bQYNGpShQ4fmxhtvrDnH2HzzzZda+5ZU+3xkr732yimnnLLUOrvJJpvk9NNPz/z581NdXZ2mTZumc+fO2WabbQqPv7W1bNkyAwYMyFe/+tU8++yzmTx5coYNG5bjjz8+HTp0SFVVVXbaaaeav9vChQsb5KfZ14RlnV8ty7L+bPF74rHHHsvuu++ebbfdNi+99FKd9XLcuHE56qijMmTIkGX+I/aOO+6YgQMHplmzZvnwww8zbdq0vPDCC3nwwQczYsSI9OnTJ8cff3xuvfXW3HXXXTX7SpLtt99+qU8++CxYHZklybnnnpuHH344CxcuTKdOnXLNNdfk1ltvrXMeWluHDh1yzDHH5Otf//py7xPcc889ueaaa3LQQQclSW666aast956qa6uzptvvllnfzvuuGMGDBiQqVOn1pmv++23X80xffE5+brrrlunSFUWqyvLnj175uqrr06SzJs3L//93/+dDTbYIFOmTMmf//zndO7cOYMGDcpHH31UZx8y/XRWV35Jaoq6l19+eZ577rk69wKWdY1b28rcN0g+Llkfd9xxeeKJJzJ79uwccMAB+d73vld4/F3SZ+H8aEWWlfvo0aPTo0ePFX76gXu3DaO+Mkvcu20I9Zmn+7f1rz7zW8z927VHUd6/+93v0qRJk6Xuk3bo0CGXX355nnzyySSpub+TZKn7OrX3W9vi1+6ee+7JIYccklatWuXf//53nXOc2q/7pptuutQ+lnc/ova9g+9///u5995788gjj2TfffetGctGG230iX9TRkNr6Mw+/PDD9O3bN3PmzMmECRPq3Fuqff5aW+17OMu7vzBhwoQMGzYse+yxR5K6x/cPPvigzv46duyYQYMGZeLEiXXuZ+y1117p2LFjzjnnnJpz+bX5nkRDZ7n4/xcXs5e8D/u73/0uF1xwQbp167bUPmS6duSXJM8++2ydc9za9xBq34NdlpW531BdXZ1TTjkl++67b/7nf/4n//73v3PooYfmwAMPLDz+Lqlz587p169f7rjjjjrrb+1ztDV5L9EnmlFv5s6dmw022KDOY+uss046dOiQP/3pTzn66KPzhz/8Iddee22OPfbYmm3atm2bf/3rX5kxY0Y6d+6cSqWS888/P+uss84Kn/O3v/1tXnjhhbzxxhtp2rRpWrduXXNBVKlU6lwcNW36cc9y9uzZSZL1118/yccH6R49euRvf/tbFixYUOd71l133SxatCivvPJK2rVrV/N4mzZtMnfu3FV9idY6DZFZkvTv3z8dOnTIpEmT6jz+4x//OH/729/Sv3//3HDDDTWPL84u+d/c/vCHP+Tggw/OhhtumIceeihNmjTJOuusk+bNmydJ4ZgW34Re/N9lvU8am4bKcoMNNkibNm3yzDPPJPn4U7gWt6z/9re/1Wy35D9gyrSuhspvsSVvJC3++qabbsq1115b8/HYRd/bsmXLNG/ePE8++WS22Wab/OAHP6h5L3z+85+vOWEeMGBAHnvssQwcODDbbrvtco+/S1qc7eJ/EK+97ZLfV9Zj9MYbb5yf//znee+993L22WfnyiuvzL/+9a/861//qvkHuOVZuHBhHnvssQwaNCjPPvts5syZs9zXsEWLFlm4cGHNepn87zydMGFCzftwyRyOP/74dO7cORdccMGn/rs3VqszsyTZaaedMmLEiCSpc/OtSZMmufLKK3Prrbdm6tSp+fGPf1znzxarfXytndvi42rz5s1TXV2d/fffP/369VvmGD766KM68+6zMPeS1Z9l8vE/lg8YMCDt2rVLdXV1OnfunN133z1JcuqppyZZ9sdsy3TV1Ud+S2rSpEnNOcbTTz+91Nq3pGWd+yy5zn7+859P8nG5/HOf+1wuv/zyjBw5Mv/+978Lj7+1Lf6JypU9J2rZsmXef//9fO5zn1vFV2Dtt6zzq1X1u9/9Lu+++24++uijpc5VVvZ685prrsnQoUNz1VVXLXU+1a5du0yZMiXNmzev8xOXjXXufVqrI7Mk+elPf5pNNtkk//Vf/1Xn8f79+9ech44aNarm8WXNzyXvEyz+dKvFx9v11ltvufO99rXJis5by2p1Zbn99ttn7Nixee+991KpVPKVr3yl5nWv/esYlyTTT2d15bcstbNZ1jXu8rZd3n2D5OPrzX/961/58MMPc+GFF+Yvf/lLLrjggsyfP3+5x98lfRbOj1ZkWbkv/jSeRx99NK+99lqda8SV5d5t/amvzBL3bhtCfebp/m39q8/8FnP/du1RlPfiX2W2ovuki+dUkqXu66zIvffem0022SRvvvnmUtc8K7u2Lvm+qf09+++/f0488cR8+ctfrrPvxZltueWWKxzj2qahM2vRokV+8YtfJEnNf5OP58UFF1xQc/5a+1cBLusYvOT9hSXHUPv4vqRVuaZp0qTJWvtDiQ2dZZIccMABOfnkk9OyZcul7sMOHz68Zr9Lkunakd+y1M6m9j3YFW27vOuVli1bpnXr1jXr6tChQ/OHP/whQ4cOzSuvvLLc4++SFmebrPi8aU2sq437bI212nbbbVfzMYW1nXjiiXniiSeSfNx4v+yyy5babuutt645AJx44ompqqpKnz596vwu3to3ghd7+umna35qZuHChencuXP69OmTs846K7vsskteeOGFDBo0KE888UTat2+fyy67LJMnT66zj7322ivDhw+v+UnIY489Nqecckp++tOfJkn22WeffO1rX6vzPa+99lq23XbbVXyF1j4NkVltu+66a5599tn07t07Bx98cO66666MHTs26623Xp3tNt988zzyyCO55557ah776le/mptvvjm//e1vk3y88Jxzzjm58847C8eUfNxwXvxTz+3atav5iaz7778/u+22W84+++z861//qtl+VUs7DaEhs+zVq1ceeOCBJMnXvva19O3bN3379s1Xv/rVTJgwIeeee27Nrz5ZTKZ1NfRc/OIXv5gzzjgjG2+8cVq0aJF33nknY8aMyZe+9KX853/+Z5577rnlfu/ibRfbfvvta35KeVmuv/763Hnnndlkk01WePyt7YEHHsgpp5ySI444Iscee2yGDh2aQYMGZebMmUk+/mnbxcp6jL777rtz6qmn5pRTTqn5Caddd901LVu2rPOeHjduXP75z3/W2def//znnHbaaRk+fHh++ctf5vbbb68zT2q/9rvuumv++Mc/5vrrr1/muIYMGZJ33303u+66a511dptttkmbNm1ywAEH1Nl+bZtv9Wl1Zrako446Kj179sz999+fb3zjGzn77LPz9NNPp23btnW223HHHdOvX7/Mnz+/5rHax4/Pf/7zqa6uzuWXX55p06Zl1113zcsvv5wzzjgjV1111VLP+7vf/S49evTICSeckJNOOqnmPKu6unqp+V+WuZfUT5YbbbRRzU+THnvssbniiivSv3//3H///fne976Xnj175o9//GPWXXfdOt8n01VXX3PxmGOOyWWXXZYzzzyz5tfWnn322Wnbtm3h2pdkmecjRevs9OnTM3jw4EydOjUbb7xxkuUff5d09tln58knn8yuu+6anXfeOQMGDMitt96anXfeOVdccUWd66EPP/ywlCWzZPnnV8uzZOmwuro6s2bNyrXXXpvrr78+//znP+usl4ccckjuvPPODBo0KC+++GI23XTTXH755Xn99dfr7GefffbJRRddlEceeSTJx792qk+fPjXnZ9ttt10OO+ywOt/TWOfep/VpM1vSwQcfnNtuuy09evTIj370ozrnobVtv/32+c1vfpPx48fXPLbkeephhx2WCy64IH/+85+TJIcffnh69uyZnj171jk+J8krr7ySgQMHpl27dkvN12Ud08t4rrQ6s+zevXvGjx+fNm3aZIMNNsiAAQNy0UUX5eCDD86NN96YSy+9dKl7CDL9dFZnfhtuuGGaNGmS/v375ytf+UqdewHLu8ZdbGXuGyzpiiuuyP33358ttthihcff2j4L50crUpT7iq4RF3Pvds2qr8yW3I97t2tGfefp/m39WhPz0f3btcfKnCsteZ/0ySefTP/+/bPnnnsute2S93UWmz59es3cWmzu3LnZeOONc+WVV+a3v/1tHnrooTrnOEu+7s2aNcsVV1yxVPlgyfdN7XsHycc/sLdkyeKNN96oU+puTBoysyUteW+p9vlrbcu6h7Pk+e3Xvva1XHbZZTX3hmof35c0ceLE9OvXLx07dlzqfsbGG2+cc889t2bbBQsWLLXWry3WliyPOOKIvPDCC0vdhz366KNz8cUXZ/To0Uvd45Xp2pPfkue4S95DWHwPdllW5n7Dki6++OI89NBD2XrrrVd4/K3tV7/6VS6++OIcffTRddbfZZ2jrZF1tcJnwsSJEytJKhMnTlxjzzlnzpzK5ZdfXi/7XrBgQeUXv/hFvey7yEsvvVT50Y9+VHn33XfrPD548ODK/Pnz1+hYxo4du9ozLWNmK+PUU09d6W1nzZpVL6/R6s5zbc3yqquuqvTt27dy1113rd5BLaGhM/20ea6t+a0t/vKXv1Ruv/32ld5+1KhRlddff/0TP199HG8/iU/6vrjiiisq77//fj2MqNhVV11VGTVqVJ3H6usYuqrWVKaNLbMV+fWvf1158sknV3r7NXV+tCbyXNNZ/v3vf6+cc845lVNOOaXy0UcfrfL3r6y1MdO16Rx3bZ2Lq2JVzokWLlxY+clPfrJan39tWUMrlVV7H7z00kuVO+64o55HtLQJEyZUunTpUqmurq7z+LnnnrvGx7I8azLTxpDZyliVefjcc89Vbr311nocTV1r4znRp8ly8ODBlR49elQeffTRT/T9K2ttzbS+8izLXFxZa8v5UUOvoZ/2voR7t0ur70wba2Yro6Hv8y1LmfP8rNy/rW1tuze/Ns/HlbWm79/WtqbX0JXJe1n3SVfVuHHjKk899dSn2scncf/991f69eu31OPnnHPOGhtDQ8zRxpzZikyZMqUydOjQld7+nnvuqTz22GOr7flXZ55re5bvvvtu5fzzz6+cfPLJlX/+85+fagxFGjLTT5Pn2p7f2uSCCy6ovP322yu9/Se9l7gqnSK/OpN606ZNm2W2SVeHVq1a5bTTTquXfRf54he/WPN7lms74IADSvGT/2tzZtdcc01N+/ioo47Krrvu+on39fjjj9f8LuXtttuu5teQrYwZM2bkhBNO+MTPvaasrVn27t275v9lunxra37L8pvf/CYvvPBCko9/Inz//fdfbfuubcn3yze/+c2V/t5ddtklW221Vb2Ma036pO+L008/ffUPZiXUnu+LrY3zrT41RGYvvPBCfvOb3yT5+FOuPu18v+yyy/L+++8nSbp165Ztttlmpb+3LOdHyZrPcqeddqr5aWCZfnprw/Fz2rRpueaaa5J8/HHmP/nJT1bbvmtb8v2yKudEb7/9do4//vh6GdfaYFXeB1/84hfzxS9+sZ5HtLQ999wzv/71r5d6/JBDDlnjY1kbrMnMPs2xcUn3339/Hn/88STJHnvssUrz8L333stRRx31iZ97bbWmsjzvvPNq/l+mq09DHj9X532DIp/F86MV+bT3Jdy7XfMaOjP3+VavhszT/dtPr6Hn45Lcv61fK5P3su6Trqpvf/vbn3ofn8Qhhxyy1DXp+++/nyOPPLJBxrM6NIbM3n///Tq/OrN///6f6tfZL3kcOOOMM1b6ezfccMPsvffen/i569PanuW6666biy++OMnHmdb+tZcyXfvzW57Veb9heT7tMWBN3EtsUqmsBb+AlXr39NNP52tf+1omTpyYPfbYo6GHw2pw88035/jjj5dpScizXORZLvIsH5mWizzLRZ7lIs/ykWm5yLNc5Fku8iwfmZaLPMtFnuUiz/KRabnIs1zkWS6r0ilquobGBAAAAAAAAAAAQCOlaAYAAAAAAAAAAEChZiu74WuvvZaZM2fW51ioR88//3yS5L777qv5fxq3Rx55JIlMy0Ke5SLPcpFn+ci0XORZLvIsF3mWj0zLRZ7lIs9ykWf5yLRc5Fku8iwXeZaPTMtFnuUiz3KZMmXKSm/bpFKpVFa00WuvvZb27dtn/vz5n2pgNKymTZumurq6oYfBaiTTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNc5Fk+Mi0XeZaLPMtFnuUj03KRZ7nIs1zWWWedjB8/Pvvss0/hdiv1iWYzZ87M/PnzM3bs2LRv3361DJA167777sv5558vwxKRabnIs1zkWS7yLB+Zlos8y0We5SLP8pFpucizXORZLvIsH5mWizzLRZ7lIs/ykWm5yLNc5Fkuzz//fI4//vi0bNlyhduu9K/OTJL27dtnjz32+MQDo+Es/qhCGZaHTMtFnuUiz3KRZ/nItFzkWS7yLBd5lo9My0We5SLPcpFn+ci0XORZLvIsF3mWj0zLRZ7lIs/PrqYNPQAAAAAAAAAAAADWbopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoFC9Fc0GDx6cJOndu/cqfd+qbl/bWWedlZ/97Ge59dZbs8cee2TmzJmfeF+LVSqVOl+PGTMmTz311FLbXXPNNendu3cuv/zyOo9fcskl6dWrV2666aYkSb9+/XLSSSflgQceyPz589OtW7fl/p0nTJiQHj165Lvf/W7eeuutPPHEE+nSpUt69uyZSqWSSy65JNXV1Z/679jYvfLKK+ncuXO6du2a+fPnJ0mmTp2aPn36pG/fvvnwww8beISsyDPPPJPDDjssd9xxx1Lv87vvvjtVVVU555xzkiQDBgxIz549s2jRogwZMiQfffRRA4+eIrXn58iRI9OzZ8+89NJLuf322/Piiy829PD4hJ588sl84xvfkGkjtqy1c9y4cdl///1rznN+9rOfpXv37rnooosacqisgDW0vKyhjZ/5WU7W0HL505/+lOOOOy5VVVUZNWpUunbtmtNOOy2VSiWDBw9OVVVVZs+enVGjRuWdd95p6OGyCmofg62jjY81tJyWtYaOHDkyJ510UqqqqpIkv/jFL9KjR4/suOOOmTt3bkMOlwLmaHm5Di2Pxx57LMccc0yOOuqo3HTTTXWuV5znNj6uQ8vDGlpe1tDGz/xcNfVSNJs4cWLat2+fJGndunVmzJiRbt265cwzz8zbb79dU6zq3bt3pk+fnh//+Mfp379/Jk2alAkTJmTUqFF57rnncvLJJ6dr166ZNWtWjjvuuJx33nnp27dvBg8enBNOOKHOc77yyiv5y1/+ki233DI/+tGP8v3vf3+ZYzvllFMyYMCA/O1vf8vtt9+e3r1756qrrspbb72Vbt26pWvXrnnppZfSo0ePDBkyJM8++2z69++fPn365L/+67/SokWLNGvWbKn9Tp48OSNGjMjUqVNrymnvv/9+5s6dm1GjRuWJJ57IK6+8km222Sa/+tWvctddd6V169a5/vrrl/s6duzYMddcc02OO+64TJkyJbfcckuuv/767L333pk4cWL23nvvjBs37hNlVCZjxozJ8OHD06VLl9x3331JktGjR6dVq1bZYIMN0rx58wYeISuy++67Z+DAgUmy1Pv8z3/+c02eM2bMSKtWrbLDDjvk0Ucfzfbbby/ftVzt+Tlq1KiccsopeeKJJzJ16tR8+ctfbujh8QlUKpXce++92X333fPmm2/KtJFa1tp58MEHp1u3bjXbTJ48Ob/85S8zd+7czJgxo6GGygpYQ8vLGtr4mZ/lZA0tl3vvvTejRo3K4YcfnjPPPDPXX399tt9++0ycODHvv/9+DjvssDz++ONp2rRpNtpoo4YeLqug9jHYdUvjYw0tp2Wtoaeeemp+9atfpWXLlnn//ffTt2/fjBo1Kvvtt1/atGnTwCNmeczR8nIdWh7PPvtsLrjggnTq1Clbb711nesV57mNj+vQ8rCGlpc1tPEzP1dNvRXNdtpppyTJkCFDctttt+WMM87I0KFDs+mmm9bZdsGCBWnTpk169uyZr371q+nYsWN69eqVG264IVdddVVOPfXU3H333amurs4ll1yS2bNnp1+/ftlmm20yb968mv1st9126dixYzp37lw4tg8++CBHHXVUdttttzz44IMZMWJE+vTpk9/+9rcZNGhQhg4dmhtvvDGLFi1Kv3798vrrr2f27NnZeOON849//CPHHXdcdtttt6X227Tpxy/lBhtskHfffTdJ8s4772TjjTeu+fNp06Zlyy23rLP9ilx77bW59tprs8MOO6RSqaRp06Zp27Zt3nrrrey88855+umnV2o/ZTZnzpxstNFGNa9Lkjz99NMZOHBgttxyyzz66KMNPEJWxZLv88VzZcstt8z06dPTrl27LFy4MOPHj8+sWbMybNiwBh4xRWrPz6qqqtxxxx2ZPn16tthii5x//vl+OrURuummm9KpU6ckyQEHHCDTRmpZa+eSjj766Jx22mmZMmWKmxONhDW0XKyh5WJ+loc1tFx69eqVc889Nw8++GAGDhyYPn365Jlnnsm0adOy6667ZtKkSXn22Wfzuc99LoMHD87ChQsbesh8Aq5bGjdraHksbw1966230rJly7Rq1SpJ8te//jX77bdfQw2TVWSOlovr0PI48MAD07dv34wePTp77bVXnT9zntv4uA4tJ2touVhDy8X8XLF6KZrNnTs3G2ywQc3XlUolTZo0+d8n/f+DmD17dr7whS/knHPOyfDhw/Pqq6/W2W6xJk2aZJNNNknycZFrvfXWS/PmzT/Rr0S88sorM3ny5Nx8883L3aZJkyZp2bJlmjdvnurq6nz/+9/PhRdemLPPPnu537P4U8zmzZuX9dZbL0my0UYbZdasWUmS6urqbL755pk2bVrN1yvjlFNOybBhw3L33XenSZMmqa6uzptvvpktttgibdq0cVBKsuGGG2b27Nk1r0uStGvXLp///OfTtm3bvPfeew08QlbFku/zxXPrrbfeyuabb56qqqp84xvfyN57751XX301TZs2ddK8Fqs9P9u2bZuzzjorLVq0yAsvvJAf/vCH+eMf/9jQQ2QV/f3vf8/o0aPz8MMPZ5111pFpI7WstXNJRxxxRK688sq0a9cuW2211RoeIZ+ENbRcrKHlYn6WhzW0XHbccceMHDky++67b/bcc8+MGDEiO++8c7bddtt06tQpXbp0yVZbbZUXX3wxX/nKV/ywXyP1ne98xzraiFlDy2NZa+jcuXNzwQUX5OKLL67Z7u67784PfvCDBholq8ocLRfXoeVx7bXX5o477shpp52WBx54oM6fOc9tfFyHlpM1tFysoeVifq5YvRTNtttuu7zxxhs1Xx977LEZOnRoBg0alJkzZ6ZZs2a54oorMnfu3Pz973/P5Zdfnnnz5mXddddNkgwbNixdunRJnz59MnLkyBxxxBGr9Px/+MMfcu+99+aMM87IggULah6vrq7O2Wefnaeffjpt27bNQQcdlD59+mTUqFE55phjctlll+XMM8+s82s5v/Od7+T3v/99zjjjjDrltLFjx+bf//53zdc77bRT+vbtm3bt2qVJkybp379/za9u7NOnTzp27Jjtt98+r776aqqqqmr+Tqeeemoeeuih3H777Zk+fXruvPPOmn3+8Y9/TK9evTJ8+PAcdNBBOfbYY9O9e/c8/vjj6dChQ1577bVsu+22q/TalFHnzp3Tr1+/jBkzJjNmzMjLL7+ck046KT169Mjvf//7HHDAAQ09RFbg5ZdfzrBhwzJ69OgcddRRdd7nBx54YHr16pUFCxZks802S5I8+OCDOeigg/LBBx/kxRdf9NHOa7Ha8/Owww7Lr3/965x44onZcsstc9111y3zEyJZu/3sZz/L8OHDs+++++Zb3/qWTBupZa2dEyZMyA033JBLL700b7zxRq677rp07949W2+9dTbccMOGHjLLYQ0tL2to42d+lpM1tFwefvjhdO/ePQ888EAWLFiQqqqqzJo1KzvvvHOSj39VwrHHHptWrVrl/vvvz5e+9KUGHjErq/YxeNKkSdbRRsYaWk7LWkP79++fWbNmpX///pkzZ04WLlyY+fPn1/khdtY+5mh5uQ4tj29961s57bTTcuONN2b99devc72SOM9tbFyHloc1tLysoY2f+bmKKith4sSJlSSViRMnrszmlTlz5lQuv/zyldq2sbrssstW+z7HjRtXeeqpp1Z6+1GjRlVef/31ldp27Nixq5Qhaz+Zlos8y0We5SLP8pFpucizXORZLvIsH5mWizzLRZ7lIs/ykWm5yLNc5Fku8iwfmZaLPMtFnuWyKr2wZvVRXmvTpk323HPP+th1HY8//njuv//+JB9/ilrnzp0/0TafxFlnnbVa9lPbt7/97VXafpdddvHxpwAAAAAAAAAAQL2rl6JZkuy33371tesae++9d/bee+9PvU1jtSZeYwAAAAAAAAAAgKYNPQAAAAAAAAAAAADWbopmAAAAAAAAAAAAFFqlX51533335fnnn6+vsVCPHnnkkSQyLBOZlos8y0We5SLP8pFpucizXORZLvIsH5mWizzLRZ7lIs/ykWm5yLNc5Fku8iwfmZaLPMtFnuUyZcqUld62SaVSqaxoo8ceeyz77bdfFi1a9KkGRsNq2rRpqqurG3oYrEYyLRd5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNc5Fk+Mi0XeZaLPMtlnXXWyfjx47PPPvsUbrdSn2jWsmXLLFq0KGPHjk379u1XywBZs+67776cf/75MiwRmZaLPMtFnuUiz/KRabnIs1zkWS7yLB+Zlos8y0We5SLP8pFpucizXORZLvIsH5mWizzLRZ7l8vzzz+f4449Py5YtV7jtKv3qzPbt22ePPfb4xAOj4Sz+qEIZlodMy0We5SLPcpFn+ci0XORZLvIsF3mWj0zLRZ7lIs9ykWf5yLRc5Fku8iwXeZaPTMtFnuUiz8+upg09AAAAAAAAAAAAANZuimYAAAAAAAAAAAAUUjSj0XrllVfSuXPndO3aNfPnz0+SjBs3Lvvvv3+eeuqpJMnPfvazdO/ePRdddFFDDpUVeOaZZ3LYYYfljjvuyBNPPJEuXbqkZ8+eqVQqufvuu1NVVZVzzjknSTJgwID07NkzixYtypAhQ/LRRx818OgpUnuejhw5Mj179sxLL72U22+/PS+++GJDD4+VYH6WkzW0PMzR8rKGNn7mZzktaw298MIL06VLl5x99tlJku7du6dHjx75+c9/3pBDZSX86U9/ynHHHZeqqqqMGjUqXbt2zWmnnZZKpZLBgwenqqoqs2fPzqhRo/LOO+809HBZBbWPwdbRxmvChAnp0aNHvvvd7+bWW29NVVVVjjzyyMyfP98cbYRch5aH89zych3a+Jmf5WQNLQ9ztLysoY2f+blq6q1oNnjw4CRJ7969V+n7VnX7FalUKoV/fs899+Qf//hHnceuueaazJkzp/D7pk6dusybxku+6RZb8s13zTXXpHfv3rn88suTfHxj+uCDD17mc82bNy89evTID37wg/z5z3/O7Nmzc+KJJ6Zz58556623csstt+Sf//xn4XjLaMyYMRk+fHi6dOmS++67L0ly8MEHp1u3bjXbTJ48Ob/85S8zd+7czJgxo6GGygrsvvvuGThwYJLklltuyfXXX5+99947EydOzJ///OeMHj06rVq1yowZM9KqVavssMMOefTRR7P99tunefPmDTx6itSep6NGjcopp5ySJ554IlOnTs2Xv/zlhh4eK8H8LCdraHmYo+VlDW38zM9yWtYa2qJFizRr1ixbbLFFkqR169aprq5O27ZtG3KorIR77703o0aNyuGHH54zzzwz119/fbbffvtMnDgx77//fg477LA8/vjjadq0aTbaaKOGHi6roPYx+M0337SONlIdO3bMNddck+OOOy7t2rXL6NGj07Fjx7zzzjvmaCPkOrQ8nOeWl+vQxs/8LCdraHmYo+VlDW38zM9VUy9Fs4kTJ6Z9+/ZJPr7BOmPGjHTr1i1nnnlm3n777ZoyWe/evTN9+vT8+Mc/Tv/+/TNp0qRMmDAho0aNynPPPZeTTz45Xbt2zaxZs3LcccflvPPOS9++fTN48OCccMIJSz3vd77znQwbNiznnXdekmSvvfbK0KFD88gjj2TAgAHp2rVr5syZk5EjR6Z///4ZO3Zs3nnnncyfPz/nnHNOBgwYkAceeCDTpk3LwoULc8UVV+SMM87IxRdfnKlTp+bwww/PJZdckjFjxqRp06Zp1arVUmNY8k232JJvvsmTJ2fEiBGZOnVqKpVKLrzwwuywww7LfD032GCDXHPNNRk1alQmTJiQu+66K6effnoGDx6cm2++OUcccUTGjh37qXNrbObMmZONNtoobdu2zVtvvbXMbY4++uicdtppmTJlihOrRqJSqaRp06Y1uTZt+vFhasstt8z06dPTrl27LFy4MOPHj8+sWbMybNiwBh4xRWrP06qqqtxxxx2ZPn16tthii5x//vmZO3duQw+RVWB+loc1tJzM0XKxhpaL+Vkey1pDzz777Fx33XV566238uabb2b48OEZPXp0xo0bl0WLFjXwiCnSq1evnHvuuXnwwQczcODA9OnTJ88880ymTZuWXXfdNZMmTcqzzz6bz33ucxk8eHAWLlzY0EPmEzjggAOso43Ytddem2uvvTY77LBDBg8enPHjx2eTTTYxRxsh16Hl5Dy3XFyHlov5WR7W0HIyR8vFGlou5ueK1VvRbKeddkqSDBkyJLfddlvOOOOMDB06NJtuummdbRcsWJA2bdqkZ8+e+epXv5qOHTumV69eueGGG3LVVVfl1FNPzd13353q6upccsklmT17dvr165dtttkm8+bNq7OvLbbYIv3790/Tpk0zZ86c7Ljjjhk4cGDGjBmT9ddfP+utt15efPHFTJ48OcOGDcvxxx9f873//ve/c+ihh+bAAw+seeyll17Kz3/+88yaNSsffvhhdtttt5x33nl5+umns8022yzz09eWfNMttuSbb/HXG2ywQd59990VvqZ/+ctfcswxx+Rb3/pWpk2bli233LLmOdZdd93P5MfDb7jhhpk9e3befPPNmp8cX9IRRxyRK6+8Mu3atctWW221hkfIJ9GkSZNUV1fX5Lr4kwHfeuutbL755qmqqso3vvGN7L333nn11VfTtGlTJ81rsdrztG3btjnrrLPSokWLvPDCC/nhD3+YP/7xjw09RFaB+Vke1tByMkfLxRpaLuZneSxrDW3SpEmSZOONN857771X8/V6662n9LCW23HHHTNy5Mjsu+++2XPPPTNixIjsvPPO2XbbbdOpU6d06dIlW221VV588cV85StfydNPP93QQ+YT+M53vmMdbcROOeWUDBs2LHfffXfOP//8nHTSSXnkkUfM0UbIdWg5Oc8tF9eh5WJ+loc1tJzM0XKxhpaL+bli9VI0mzt3bjbYYIOaryuVSs2N1uR/S1ezZ8/OF77whZxzzjkZPnx4Xn311TrbLdakSZNssskmST4uZq233npp3rx5PvzwwzrbLf7dp4v/u/7669c8//nnn5+rrroqHTt2XOZzDB06NO+++26GDh1a53lr+/znP58kqa6uXu7ffck3Xe3XIPnfN9/ir+fNm5f11ltvuftb7MADD8z/+3//LzfffHM233zzTJs2rfCE4rOgc+fO6devX8aMGZMZM2bk5ZdfzoQJE3LDDTfk0ksvzRtvvJHrrrsu3bt3z9Zbb50NN9ywoYfMcrz88ssZNmxYRo8enaOOOirdu3fP448/ng4dOuTAAw9Mr169smDBgmy22WZJkgcffDAHHXRQPvjgg7z44ot+PcJarPY8Peyww/LrX/86J554Yrbccstcd9112W233Rp6iKyA+VlO1tDyMEfLyxra+Jmf5bSsNXTIkCGpqqrK1KlT86UvfSlnnXVWunfvno033jgtW7Zs6CFT4OGHH0737t3zwAMPZMGCBamqqsqsWbOy8847J/n4U+uPPfbYtGrVKvfff3++9KUvNfCIWVm1j8GTJk2yjjZSf/zjH9OrV68MHz48M2bMSK9evXLPPffka1/7WhJztLFxHVoeznPLy3Vo42d+lpM1tDzM0fKyhjZ+5ucqqqyEiRMnVpJUJk6cuDKbV+64447KY489VvP19OnTK127dq2cddZZlbfffrvSr1+/yrBhwyqHH354ZfLkyZXTTz+9cvzxx1fefvvtSu/evSuXX3555bnnnqucdNJJlS5dulRmzpxZOfXUUyuVSqXmvxdccEHl7bffrvO8hx56aOWss86qDBgwoM62f/3rXyvdunWr9O7duzJlypTKiBEjKv3796/ccsstlV//+teVJ598snL22WdXTjvttMrNN99cs+9hw4ZVBgwYULnooosqU6ZMqQwdOrTOfiuVSmXSpEmVhx9+uObrRx99tNKtW7dKjx49KtXV1ZVBgwZV3n///crvfve7Ss+ePSuDBg2qVCqVyqhRoyqnnXZazT6HDx9e2XnnnSuXXHJJpVKpVEaOHFmzz1deeaXSs2fPSteuXSu///3vK7NmzaqceOKJlc6dO1feeOONSqVSqZx++umFmYwdO3aVMmTtJ9NykWe5yLNc5Fk+Mi0XeZaLPMtFnuUj03KRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXFalF9asPspr3/72t/OrX/0qe++9d5Jks802y/XXX1/z54t/R2m/fv2SJFdccUXNn1111VU1/3/dddfV/P+IESPq/PfCCy9c6nm33377XHbZZUt9z3777Zf99tuv5vFTTz11qe/t0KHDUo8tHt9iZ5xxRp39JskzzzyTQw45pObrffbZJ/vss0/N15deemmS5KijjspRRx1V83jPnj3r7Ltv377p27dvkuT999+v8+s1tt1224waNarO9mPGjKn5/8mTJ2evvfZaavwAAAAAAAAAAACrQ70Uzdq0aZM999yzPnZdx+OPP577778/SbLddtvVKYCtKSeeeOJq32erVq1y2mmnrfT27733Xp0SGwAAAAAAAAAAwOpUL0WzJHU+Qay+7L333jWfmvZZ5tPMAAAAAAAAAACA+tS0oQcAAAAAAAAAAADA2k3RDAAAAAAAAAAAgEKr9Ksz77vvvjz//PP1NRbq0SOPPJJEhmUi03KRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNcpkyZstLbNqlUKpUVbfTYY49lv/32y6JFiz7VwGhYTZs2TXV1dUMPg9VIpuUiz3KRZ7nIs3xkWi7yLBd5los8y0em5SLPcpFnucizfGRaLvIsF3mWizzLR6blIs9ykWe5rLPOOhk/fnz22Wefwu1W6hPNWrZsmUWLFmXs2LFp3779ahkga9Z9992X888/X4YlItNykWe5yLNc5Fk+Mi0XeZaLPMtFnuUj03KRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXJ5//vkcf/zxadmy5Qq3XaVfndm+ffvssccen3hgNJzFH1Uow/KQabnIs1zkWS7yLB+Zlos8y0We5SLP8pFpucizXORZLvIsH5mWizzLRZ7lIs/ykWm5yLNc5PnZ1bShBwAAAAAAAAAAAMDaTdEMAAAAAAAAAACAQvVWNBs8eHCSpHfv3qv0fau6/bJUKpWV3vbCCy/MzJkza553Wc//yiuvpHPnzunatWvmz59f8/gTTzyRLl26pGfPnqlUKrn77rtTVVWVc845J0kyYsSIwo8IPPXUU9OpU6fcdNNNWbhwYU4++eSceOKJmTx5ch555JE88MADK/33+CxbVj4jR47MSSedlKqqqgYeHSvjmWeeyWGHHZY77rhjhfNqwIAB6dmzZxYtWpQhQ4bko48+auDRU6T2/Bw5cmR69uyZl156KbfffntefPHFhh4eq+BPf/pTjjvuuFRVVeXmm2/Oj3/84xxzzDFZsGBBBg8enKqqqsyePTujRo3KO++809DDZSVZQxs/a2h5WUPLo/YaOmrUqHTt2jWnnXZaKpWKNbQRWtbaOW7cuOy///556qmnkiQ/+9nP0r1791x00UUNOVRWwBpaXtbQxs/8LKdlraFTp05Nnz590rdv33z44Ye5+OKL06VLl5x33nkNPFpW1uzZs3P66aenT58+ueiiixxzG6na1yzz58/PXXfdlWOOOSZJXLM0cmPGjMkPf/jD9OjRw3lRI+Y6tDyc55aX69DGz/xcNfVSNJs4cWLat2+fJGndunVmzJiRbt265cwzz8zbb79dp9Q1ffr0/PjHP07//v0zadKkTJgwIaNGjcpzzz2Xk08+OV27ds2sWbNy3HHH5bzzzkvfvn0zePDgnHDCCUs97yGHHJIhQ4bk2WefTd++fdOtW7e88soruf3229O7d+9cddVVee2113LuueemS5cumTt37lL7aN269VKPjRkzJsOHD0+XLl1y33331Tx+yy235Prrr8/ee++diRMn5s9//nNGjx6dVq1aZcaMGendu3e+/vWvL/d1GjlyZG6++eZMnDgxf/3rX3P44Yfn2muvzZgxY/L1r389f/zjH1f5tf8sWlY+p556an71q1+lZcuWef/99xt4hKzI7rvvnoEDByZZ8bxq1apVdthhhzz66KPZfvvt07x58wYePUVqz89Ro0bllFNOyRNPPJGpU6fmy1/+ckMPj1Vw7733ZtSoUTn88MPz05/+NNdee22+9rWvZfr06Xn//fdz2GGH5fHHH0/Tpk2z0UYbNfRwWUnW0MbPGlpe1tDyqL2Gnnnmmbn++uuz/fbbZ+LEidbQRmhZa+fBBx+cbt261WwzefLk/PKXv8zcuXMzY8aMhhoqK2ANLS9raONnfpbTstbQxVlusMEGad68eX7yk59kzJgxmT59egOPlpV13XXXpUWLFmnevHnmzZvnmNtI1b5m+d3vfpcXXnghm222WZK4Zmnk1llnnbRq1Sqbbrpp3nzzTXO0kXIdWh7Oc8vLdWjjZ36umnormu20005JkiFDhuS2227LGWeckaFDh2bTTTets+2CBQvSpk2b9OzZM1/96lfTsWPH9OrVKzfccEOuuuqqnHrqqbn77rtTXV2dSy65JLNnz06/fv2yzTbbZN68eXX2tcUWW2TgwIG55ZZb0qZNm2y88caZPHlyHnzwwYwYMSJ9+vRJs2bN8sEHH2TRokV5+OGHlxr7kCFDlnpszpw52WijjdK2bdu89dZbNY9XKpU0bdq05vGmTT9+ObfccsuVuhieNGlSDjnkkHzzm9/MtGnTsuWWW6ZVq1b58MMP06RJE/+4u5KWl89bb72Vli1bplWrVg04OlbViuZVu3btsnDhwowfPz6zZs3KsGHDGnjEFKk9P6uqqnLHHXdk+vTp2WKLLXL++ecvs/DL2qlXr14599xz8+CDD6ZTp0458sgj89hjj+ULX/hCdt1110yaNCnPPvtsPve5z2Xw4MFZuHBhQw+ZlWANLRdraLlYQ8uj9ho6cODA9OnTJ88880ymTZtmDW2Elrd21nb00UfntNNOy5QpU9zgbySsoeViDS0X87M8lrWGPv300xk4cGC23HLLPProo0mSv//979l2220bcqisgn/+85/p1KlTvv3tb2fXXXd1zG2kal+zTJkyJSeffHLNn7lmadyOP/743Hzzzdlyyy3TsmVLc7SRch1aTs5zy8V1aLmYnytWL0WzuXPnZoMNNqj5ulKppEmTJv/7pP9/ELNnz84XvvCFnHPOORk+fHheffXVOtst1qRJk2yyySZJkg022CDrrbdemjdvng8//LDOduuvv36SZOHChTn99NMzdOjQfP/736+zzc0335wePXrkiCOOyIIFC1bq77Phhhtm9uzZefPNN7PFFlvUGVd1dXXN44t/Zedbb72VzTfffIX7/epXv5oHHnggf/rTn7L55ptn2rRp+eCDDz6TjcdPY1n5zJ07NxdccEEuvvjiBh4dq2pF86qqqirf+MY3svfee+fVV19N06ZNnTSvxWrPz7Zt2+ass85KixYt8sILL+SHP/yhT25sRHbccceMHDky++67b2644Yb86U9/yoEHHpjJkyenU6dO6dKlS7baaqu8+OKL+cpXvpKnn366oYfMSrCGlos1tFysoeVRew3dc889M2LEiOy8887ZdtttraGN0PLuD9R2xBFH5Morr0y7du2y1VZbreER8klYQ8vFGlou5md5LGsNbdeuXT7/+c+nbdu2ee+99/L666/n6quvzqBBgxp4tKyszTffPFtssUXatm2bDz74wDG3kap9zXLTTTflpz/9aR5++OE888wzrlkaucX/5rrppptmn332MUcbKdeh5eQ8t1xch5aL+bli9VI022677fLGG2/UfH3sscdm6NChGTRoUGbOnJlmzZrliiuuyNy5c/P3v/89l19+eebNm5d11103STJs2LB06dIlffr0yciRI3PEEUes0vN37949/fr1y+mnn56nnnoqBx10UPr06ZNRo0Zlr732yvDhw/OHP/xhud8/ffr03HnnnTVfd+7cOf369cuYMWNy2GGHZdSoUXn55Zdz7LHHpnv37nn88cfToUOHHHjggenVq1cWLFiQzTbbLGPHjs1DDz2U/v37J0lGjRpVs8958+alV69eqaqqSocOHbL//vvnv//7v9OjR4+ceOKJST7+SFtWrHY+M2bMyMsvv5z+/ftn1qxZ6d+/f+bMmdPQQ2QFXn755QwbNiyjR4/OUUcdVTivkuTBBx/MQQcdlA8++CAvvviij+teiy15/Pz1r3+dE088MVtuuWWuu+667Lbbbg09RFbSww8/nO7du+eBBx7Iueeem6qqqowfPz7bbLNNko8/RvbYY49Nq1atcv/99+dLX/pSA4+YlWENbfysoeVlDS2P2mvoggULUlVVlVmzZmXnnXdOYg1tbJa1dk6YMCE33HBDLr300rzxxhu57rrr0r1792y99dbZcMMNG3rILIc1tLysoY2f+VlOy1pDTzrppPTo0SO///3vc8ABB6Rr166ZN29e+vTp09DDZSV17do15513XoYPH54jjzzSMbeRqn3N8sILL2T48OHZd999s/vuuydxzdKYXX/99amqqqo5zpqjjZPr0PJwnlterkMbP/NzFVVWwsSJEytJKhMnTlyZzStz5sypXH755Su17dpo3Lhxlaeeemq17/eyyy5b6W1nzZq1Wl/DsWPHrlKGrP1kWi7yLBd5los8y0em5SLPcpFnucizfGRaLvIsF3mWizzLR6blIs9ykWe5yLN8ZFou8iwXeZbLqvTCmtVHea1NmzbZc88962PXdTz++OO5//77k3z8KWqdO3deLfv99re/vVr2s6SzzjprpbedMWNGTjjhhHoZBwAAAAAAAAAAwKqol6JZkuy33371tesae++9d/bee+96f56GsOOOOzb0EAAAAAAAAAAAAJIkTRt6AAAAAAAAAAAAAKzdFM0AAAAAAAAAAAAotEq/OvP555+vr3FQz6ZMmZJEhmUi03KRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXORZPjItF3mWizzLRZ7lI9NykWe5yLNcViXHJpVKpbKijV577bW0b98+8+fP/1QDo2Gts846WbRoUUMPg9VIpuUiz3KRZ7nIs3xkWi7yLBd5los8y0em5SLPcpFnucizfGRaLvIsF3mWizzLR6blIs9ykWe5tG7dOs8//3y22Wabwu1WqmiWfFw2mzlz5moZHA3jgw8+SMuWLRt6GKxGMi0XeZaLPMtFnuUj03KRZ7nIs1zkWT4yLRd5los8y0We5SPTcpFnucizXORZPjItF3mWizzLZZNNNllhySxZhaIZAAAAAAAAAAAAn01NG3oAAAAAAAAAAAAArN0UzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQSNEMAAAAAAAAAACAQopmAAAAAAAAAAAAFFI0AwAAAAAAAAAAoJCiGQAAAAAAAAAAAIUUzQAAAAAAAAAAACikaAYAAAAAAAAAAEAhRTMAAAAAAAAAAAAKKZoBAAAAAAAAAABQ6P8DH7NDL6n2zp4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 3000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the figure with a white background\n",
    "plt.figure(figsize=(30, 6), facecolor='white')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)  # Adjust the font size\n",
    "ax = plt.gca()\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Define row colors: all rows with no color (white background)\n",
    "row_colors = ['white'] * len(trade_summary_day.index)\n",
    "\n",
    "# Create the table with no color\n",
    "table = ax.table(\n",
    "    cellText=trade_summary_day.values,\n",
    "    colLabels=trade_summary_day.columns,\n",
    "    rowLabels=trade_summary_day .index,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    cellColours=[['white'] * len(trade_summary_day.columns) for _ in range(len(trade_summary_day))],  # No color for cells\n",
    "    colColours=['white'] * len(trade_summary_day.columns),  # No color for column labels\n",
    "    rowColours=row_colors  # No color for row labels\n",
    ")\n",
    "\n",
    "# Style the cells to have black text on the white background\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    cell.set_text_props(color='black')  # Set text color to black\n",
    "    cell.set_edgecolor('black')  # Set edge color to black\n",
    "\n",
    "# Save the figure as a PNG\n",
    "plt.savefig('lstm_trade_summary_day.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8452f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2d3b6fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Naive</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SV</th>\n",
       "      <th colspan=\"4\" halign=\"left\">TI</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Full</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Hybrid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos_trade_pct</th>\n",
       "      <th>Neg_trade_pct</th>\n",
       "      <th>Total_transac_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(metric, learning_rate, epochs)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(custom_f1_score, 0.001, 30)</th>\n",
       "      <td>0.18</td>\n",
       "      <td>99%</td>\n",
       "      <td>1%</td>\n",
       "      <td>100%</td>\n",
       "      <td>0.51</td>\n",
       "      <td>81%</td>\n",
       "      <td>19%</td>\n",
       "      <td>27%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2%</td>\n",
       "      <td>98%</td>\n",
       "      <td>8%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>46%</td>\n",
       "      <td>54%</td>\n",
       "      <td>6%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>66%</td>\n",
       "      <td>34%</td>\n",
       "      <td>5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(custom_precision, 0.001, 30)</th>\n",
       "      <td>0.63</td>\n",
       "      <td>67%</td>\n",
       "      <td>33%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.59</td>\n",
       "      <td>69%</td>\n",
       "      <td>31%</td>\n",
       "      <td>17%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>42%</td>\n",
       "      <td>58%</td>\n",
       "      <td>12%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>30%</td>\n",
       "      <td>70%</td>\n",
       "      <td>13%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>39%</td>\n",
       "      <td>61%</td>\n",
       "      <td>8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(custom_recall, 0.001, 30)</th>\n",
       "      <td>0.39</td>\n",
       "      <td>66%</td>\n",
       "      <td>34%</td>\n",
       "      <td>59%</td>\n",
       "      <td>0.58</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>19%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>4%</td>\n",
       "      <td>96%</td>\n",
       "      <td>8%</td>\n",
       "      <td>0.62</td>\n",
       "      <td>100%</td>\n",
       "      <td>0%</td>\n",
       "      <td>15%</td>\n",
       "      <td>0.63</td>\n",
       "      <td>69%</td>\n",
       "      <td>31%</td>\n",
       "      <td>7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Naive                              \\\n",
       "                                Accuracy Pos_trade_pct Neg_trade_pct   \n",
       "(metric, learning_rate, epochs)                                        \n",
       "(custom_f1_score, 0.001, 30)        0.18           99%            1%   \n",
       "(custom_precision, 0.001, 30)       0.63           67%           33%   \n",
       "(custom_recall, 0.001, 30)          0.39           66%           34%   \n",
       "\n",
       "                                                        SV                \\\n",
       "                                Total_transac_pct Accuracy Pos_trade_pct   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)                 100%     0.51           81%   \n",
       "(custom_precision, 0.001, 30)                  0%     0.59           69%   \n",
       "(custom_recall, 0.001, 30)                    59%     0.58          100%   \n",
       "\n",
       "                                                                      TI  \\\n",
       "                                Neg_trade_pct Total_transac_pct Accuracy   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)              19%               27%     0.63   \n",
       "(custom_precision, 0.001, 30)             31%               17%     0.63   \n",
       "(custom_recall, 0.001, 30)                 0%               19%     0.63   \n",
       "\n",
       "                                                                               \\\n",
       "                                Pos_trade_pct Neg_trade_pct Total_transac_pct   \n",
       "(metric, learning_rate, epochs)                                                 \n",
       "(custom_f1_score, 0.001, 30)               2%           98%                8%   \n",
       "(custom_precision, 0.001, 30)             42%           58%               12%   \n",
       "(custom_recall, 0.001, 30)                 4%           96%                8%   \n",
       "\n",
       "                                    Full                              \\\n",
       "                                Accuracy Pos_trade_pct Neg_trade_pct   \n",
       "(metric, learning_rate, epochs)                                        \n",
       "(custom_f1_score, 0.001, 30)        0.63           46%           54%   \n",
       "(custom_precision, 0.001, 30)       0.63           30%           70%   \n",
       "(custom_recall, 0.001, 30)          0.62          100%            0%   \n",
       "\n",
       "                                                    Hybrid                \\\n",
       "                                Total_transac_pct Accuracy Pos_trade_pct   \n",
       "(metric, learning_rate, epochs)                                            \n",
       "(custom_f1_score, 0.001, 30)                   6%     0.63           66%   \n",
       "(custom_precision, 0.001, 30)                 13%     0.63           39%   \n",
       "(custom_recall, 0.001, 30)                    15%     0.63           69%   \n",
       "\n",
       "                                                                 \n",
       "                                Neg_trade_pct Total_transac_pct  \n",
       "(metric, learning_rate, epochs)                                  \n",
       "(custom_f1_score, 0.001, 30)              34%                5%  \n",
       "(custom_precision, 0.001, 30)             61%                8%  \n",
       "(custom_recall, 0.001, 30)                31%                7%  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date = datetime.now().date()\n",
    "run_name1 = f'quantile_upper_{quantile_upper}_{accuracy_metric}_{date(2024, 8, 19)}_{target_used}_hourly_data_grid_search'\n",
    "with open(f'results_Naive_{run_name1}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Naive, file)\n",
    "\n",
    "with open(f'results_SV_{run_name1}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_SV, file)\n",
    "\n",
    "with open(f'results_TI_{run_name1}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_TI, file)\n",
    "\n",
    "with open(f'results_Full_{run_name1}.pkl', 'wb') as file:\n",
    "    pickle.dump(results_Full, file)\n",
    "\n",
    "# Load the saved results from the pickle files\n",
    "with open(f'results_Naive_{run_name1}.pkl', 'rb') as file:\n",
    "    results_Naive_hour = pickle.load(file)\n",
    "\n",
    "with open(f'results_SV_{run_name1}.pkl', 'rb') as file:\n",
    "    results_SV_hour = pickle.load(file)\n",
    "\n",
    "with open(f'results_TI_{run_name1}.pkl', 'rb') as file:\n",
    "    results_TI_hour = pickle.load(file)\n",
    "\n",
    "with open(f'results_Full_{run_name1}.pkl', 'rb') as file:\n",
    "    results_Full_hour = pickle.load(file)\n",
    "\n",
    "epochs_list = [30]\n",
    "models = ['Naive','SV', 'TI', 'Full', 'Hybrid'] \n",
    "results_hour = {\n",
    "    'Naive': results_Naive_hour,\n",
    "    'SV': results_SV_hour,\n",
    "    'TI': results_TI_hour,\n",
    "    'Full': results_Full_hour,\n",
    "    'Hybrid': generate_hybrid_predictions(metric_list,learn_rate_list, epochs_list,  results_SV_hour, results_TI_hour, create_hybrid_predictions)\n",
    "}\n",
    "\n",
    "trade_summary_hour = create_trade_summary(y_test, results_hour, metric_list,learn_rate_list, epochs_list, models)\n",
    "trade_summary_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e6bf337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the figure with a white background\n",
    "plt.figure(figsize=(30, 6), facecolor='white')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)  # Adjust the font size\n",
    "ax = plt.gca()\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Define row colors: all rows with no color (white background)\n",
    "row_colors = ['white'] * len(trade_summary_hour.index)\n",
    "\n",
    "# Create the table with no color\n",
    "table = ax.table(\n",
    "    cellText=trade_summary_hour.values,\n",
    "    colLabels=trade_summary_hour.columns,\n",
    "    rowLabels=trade_summary_hour .index,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    cellColours=[['white'] * len(trade_summary_hour.columns) for _ in range(len(trade_summary_hour))],  # No color for cells\n",
    "    colColours=['white'] * len(trade_summary_hour.columns),  # No color for column labels\n",
    "    rowColours=row_colors  # No color for row labels\n",
    ")\n",
    "\n",
    "# Style the cells to have black text on the white background\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    cell.set_text_props(color='black')  # Set text color to black\n",
    "    cell.set_edgecolor('black')  # Set edge color to black\n",
    "\n",
    "# Save the figure as a PNG\n",
    "plt.savefig('lstm_trade_summary_hour.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(results, y_test, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1be310",
   "metadata": {},
   "source": [
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55878fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27c391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22d0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815ce9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dede92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
